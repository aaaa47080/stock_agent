"""
å¿«å–ç®¡ç†æ¨¡çµ„
æä¾›æŸ¥è©¢å¿«å–ã€Planning å¿«å–å’Œè¨˜æ†¶é«”ç®¡ç†åŠŸèƒ½
æ”¯æ´ Valkey/Redis åˆ†æ•£å¼å¿«å–
"""

import hashlib
import time
import pickle
from typing import Any, Optional, Dict, Tuple
from collections import OrderedDict
from functools import wraps

try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    print("âš ï¸ Redis å®¢æˆ¶ç«¯æœªå®‰è£ï¼Œå°‡ä½¿ç”¨è¨˜æ†¶é«”å¿«å–")


class LRUCache:
    """LRU (Least Recently Used) å¿«å–å¯¦ç¾"""

    def __init__(self, max_size: int = 100, ttl: int = 3600):
        """
        Args:
            max_size: æœ€å¤§å¿«å–æ¢ç›®æ•¸
            ttl: å¿«å–æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        """
        self.max_size = max_size
        self.ttl = ttl
        self.cache: OrderedDict = OrderedDict()
        self.timestamps: Dict[str, float] = {}
        self.hit_count = 0
        self.miss_count = 0

    def _is_expired(self, key: str) -> bool:
        """æª¢æŸ¥å¿«å–æ˜¯å¦éæœŸ"""
        if key not in self.timestamps:
            return True
        return (time.time() - self.timestamps[key]) > self.ttl

    def get(self, key: str) -> Optional[Any]:
        """ç²å–å¿«å–å€¼"""
        if key not in self.cache or self._is_expired(key):
            self.miss_count += 1
            if key in self.cache:
                # éæœŸå‰‡åˆªé™¤
                del self.cache[key]
                del self.timestamps[key]
            return None

        # ç§»å‹•åˆ°æœ€å¾Œï¼ˆè¡¨ç¤ºæœ€è¿‘ä½¿ç”¨ï¼‰
        self.cache.move_to_end(key)
        self.hit_count += 1
        return self.cache[key]

    def set(self, key: str, value: Any):
        """è¨­ç½®å¿«å–å€¼"""
        if key in self.cache:
            # æ›´æ–°ç¾æœ‰å¿«å–
            self.cache.move_to_end(key)
            self.cache[key] = value
            self.timestamps[key] = time.time()
        else:
            # æ–°å¢å¿«å– - æª¢æŸ¥æ˜¯å¦å·²æ»¿
            if len(self.cache) >= self.max_size:
                # ç§»é™¤æœ€èˆŠçš„æ¢ç›®ï¼ˆç¬¬ä¸€å€‹é …ç›®ï¼‰
                oldest_key = next(iter(self.cache))
                del self.cache[oldest_key]
                del self.timestamps[oldest_key]

            # æ·»åŠ æ–°é …ç›®
            self.cache[key] = value
            self.timestamps[key] = time.time()

    def clear(self):
        """æ¸…ç©ºå¿«å–"""
        self.cache.clear()
        self.timestamps.clear()
        self.hit_count = 0
        self.miss_count = 0

    def get_stats(self) -> Dict[str, Any]:
        """ç²å–å¿«å–çµ±è¨ˆ"""
        total_requests = self.hit_count + self.miss_count
        hit_rate = self.hit_count / total_requests if total_requests > 0 else 0

        return {
            "size": len(self.cache),
            "max_size": self.max_size,
            "hit_count": self.hit_count,
            "miss_count": self.miss_count,
            "hit_rate": hit_rate,
            "ttl": self.ttl
        }


class ValkeyCache:
    """Valkey/Redis åˆ†æ•£å¼å¿«å–å¯¦ç¾"""

    def __init__(self, host: str = "localhost", port: int = 6380, db: int = 0,
                 password: Optional[str] = None, ttl: int = 3600, prefix: str = "cache"):
        """
        Args:
            host: Valkey/Redis ä¸»æ©Ÿ
            port: Valkey/Redis ç«¯å£
            db: è³‡æ–™åº«ç·¨è™Ÿ
            password: å¯†ç¢¼ï¼ˆå¯é¸ï¼‰
            ttl: å¿«å–æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
            prefix: éµå‰ç¶´ï¼ˆç”¨æ–¼å€åˆ†ä¸åŒé¡å‹çš„å¿«å–ï¼‰
        """
        if not REDIS_AVAILABLE:
            raise ImportError("Redis å®¢æˆ¶ç«¯æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install redis")

        self.ttl = ttl
        self.prefix = prefix
        self.hit_count = 0
        self.miss_count = 0

        # é€£æ¥ Valkey/Redis
        self.client = redis.Redis(
            host=host,
            port=port,
            db=db,
            password=password,
            decode_responses=False,  # ä¸è‡ªå‹•è§£ç¢¼ï¼Œæˆ‘å€‘ä½¿ç”¨ pickle
            socket_connect_timeout=5,
            socket_timeout=5
        )

        # æ¸¬è©¦é€£æ¥
        try:
            self.client.ping()
            print(f"âœ… å·²é€£æ¥åˆ° Valkey/Redis: {host}:{port} (DB {db})")
        except Exception as e:
            print(f"âŒ ç„¡æ³•é€£æ¥åˆ° Valkey/Redis: {e}")
            raise

    def _make_key(self, key: str) -> str:
        """ç”Ÿæˆå®Œæ•´çš„éµå"""
        return f"{self.prefix}:{key}"

    def get(self, key: str) -> Optional[Any]:
        """ç²å–å¿«å–å€¼"""
        try:
            full_key = self._make_key(key)
            value = self.client.get(full_key)

            if value is None:
                self.miss_count += 1
                return None

            self.hit_count += 1
            # ä½¿ç”¨ pickle ååºåˆ—åŒ–
            return pickle.loads(value)

        except Exception as e:
            print(f"âš ï¸ Valkey get éŒ¯èª¤: {e}")
            self.miss_count += 1
            return None

    def set(self, key: str, value: Any):
        """è¨­ç½®å¿«å–å€¼"""
        try:
            full_key = self._make_key(key)
            # ä½¿ç”¨ pickle åºåˆ—åŒ–ï¼ˆæ”¯æ´è¤‡é›œ Python ç‰©ä»¶ï¼‰
            serialized = pickle.dumps(value)
            self.client.setex(full_key, self.ttl, serialized)

        except Exception as e:
            print(f"âš ï¸ Valkey set éŒ¯èª¤: {e}")

    def clear(self):
        """æ¸…ç©ºå¿«å–ï¼ˆåªæ¸…é™¤ç•¶å‰ prefix çš„éµï¼‰"""
        try:
            # ä½¿ç”¨ SCAN ä¾†é¿å…é˜»å¡
            cursor = 0
            pattern = f"{self.prefix}:*"
            deleted_count = 0

            while True:
                cursor, keys = self.client.scan(cursor, match=pattern, count=100)
                if keys:
                    self.client.delete(*keys)
                    deleted_count += len(keys)
                if cursor == 0:
                    break

            self.hit_count = 0
            self.miss_count = 0
            print(f"ğŸ—‘ï¸ å·²æ¸…ç©º {deleted_count} å€‹å¿«å–éµï¼ˆprefix: {self.prefix}ï¼‰")

        except Exception as e:
            print(f"âš ï¸ Valkey clear éŒ¯èª¤: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """ç²å–å¿«å–çµ±è¨ˆ"""
        total_requests = self.hit_count + self.miss_count
        hit_rate = self.hit_count / total_requests if total_requests > 0 else 0

        try:
            # ç²å–ç•¶å‰ prefix çš„éµæ•¸é‡
            cursor = 0
            pattern = f"{self.prefix}:*"
            size = 0

            while True:
                cursor, keys = self.client.scan(cursor, match=pattern, count=100)
                size += len(keys)
                if cursor == 0:
                    break

        except Exception:
            size = -1  # éŒ¯èª¤æ™‚è¿”å› -1

        return {
            "size": size,
            "max_size": "unlimited",
            "hit_count": self.hit_count,
            "miss_count": self.miss_count,
            "hit_rate": hit_rate,
            "ttl": self.ttl,
            "prefix": self.prefix
        }


class CacheManager:
    """çµ±ä¸€çš„å¿«å–ç®¡ç†å™¨"""

    def __init__(self, config: Dict[str, Any]):
        """
        Args:
            config: å¿«å–é…ç½®å­—å…¸
        """
        self.config = config

        # æ±ºå®šä½¿ç”¨å“ªç¨®å¿«å–å¯¦ç¾
        use_valkey = config.get('use_valkey', False)
        valkey_config = config.get('valkey', {})

        def _create_cache(cache_type: str, enabled_key: str, ttl_key: str, size_key: str = None, default_ttl: int = 3600):
            """å‰µå»ºå¿«å–å¯¦ä¾‹çš„è¼”åŠ©å‡½æ•¸"""
            if not config.get(enabled_key, True):
                return None

            if use_valkey and REDIS_AVAILABLE:
                try:
                    return ValkeyCache(
                        host=valkey_config.get('host', 'localhost'),
                        port=valkey_config.get('port', 6380),
                        db=valkey_config.get('db', 0),
                        password=valkey_config.get('password'),
                        ttl=config.get(ttl_key, default_ttl),
                        prefix=f"{cache_type}"
                    )
                except Exception as e:
                    print(f"âš ï¸ Valkey é€£æ¥å¤±æ•—ï¼Œå›é€€åˆ°è¨˜æ†¶é«”å¿«å–: {e}")
                    # å›é€€åˆ° LRUCache
                    return LRUCache(
                        max_size=config.get(size_key, 100) if size_key else 100,
                        ttl=config.get(ttl_key, default_ttl)
                    )
            else:
                return LRUCache(
                    max_size=config.get(size_key, 100) if size_key else 100,
                    ttl=config.get(ttl_key, default_ttl)
                )

        # æŸ¥è©¢å¿«å–ï¼ˆç›¸ä¼¼æŸ¥è©¢çš„æœ€çµ‚ç­”æ¡ˆï¼‰
        self.query_cache = _create_cache(
            'query_cache',
            'enable_query_cache',
            'query_cache_ttl',
            'query_cache_size',
            3600
        )

        # Planning çµæœå¿«å–
        self.planning_cache = _create_cache(
            'planning_cache',
            'enable_planning_cache',
            'planning_cache_ttl',
            'planning_cache_size',
            7200
        )

        # æª¢ç´¢çµæœå¿«å–
        self.retrieval_cache = _create_cache(
            'retrieval_cache',
            'enable_retrieval_cache',
            'retrieval_cache_ttl',
            'retrieval_cache_size',
            1800
        )

        cache_backend = "Valkey/Redis" if use_valkey and REDIS_AVAILABLE else "è¨˜æ†¶é«” (LRU)"
        print(f"âœ… CacheManager åˆå§‹åŒ–å®Œæˆï¼ˆå¾Œç«¯: {cache_backend}ï¼‰")
        if self.query_cache:
            stats = self.query_cache.get_stats()
            print(f"   - æŸ¥è©¢å¿«å–: ttl={stats['ttl']}s")
        if self.planning_cache:
            stats = self.planning_cache.get_stats()
            print(f"   - Planning å¿«å–: ttl={stats['ttl']}s")
        if self.retrieval_cache:
            stats = self.retrieval_cache.get_stats()
            print(f"   - æª¢ç´¢å¿«å–: ttl={stats['ttl']}s")

    @staticmethod
    def generate_key(*args, **kwargs) -> str:
        """ç”Ÿæˆå¿«å–éµï¼ˆåŸºæ–¼åƒæ•¸çš„ hashï¼‰"""
        # å°‡åƒæ•¸è½‰æ›ç‚ºå­—ä¸²
        key_parts = [str(arg) for arg in args]
        key_parts.extend([f"{k}={v}" for k, v in sorted(kwargs.items())])
        key_str = "|".join(key_parts)

        # ç”Ÿæˆ MD5 hash
        return hashlib.md5(key_str.encode('utf-8')).hexdigest()

    def get_query_cache(self, query: str, user_id: str = "") -> Optional[Any]:
        """ç²å–æŸ¥è©¢å¿«å–"""
        if not self.query_cache:
            return None

        key = self.generate_key(query, user_id)
        return self.query_cache.get(key)

    def set_query_cache(self, query: str, result: Any, user_id: str = ""):
        """è¨­ç½®æŸ¥è©¢å¿«å–"""
        if not self.query_cache:
            return

        key = self.generate_key(query, user_id)
        self.query_cache.set(key, result)

    def get_planning_cache(self, query: str, context: str = "", user_id: str = "") -> Optional[Any]:
        """
        ç²å– Planning å¿«å–

        ğŸ”’ éš±ç§å„ªå…ˆç­–ç•¥ï¼š
        - ç¸½æ˜¯ä½¿ç”¨ user_id éš”é›¢ä¸åŒç”¨æˆ¶ï¼ˆé¿å…ä¸»å•é¡Œä¸­çš„å€‹äººä¿¡æ¯æ³„éœ²ï¼‰
        """
        if not self.planning_cache:
            return None

        # ğŸ”’ å¼·åˆ¶åŒ…å« user_idï¼Œé¿å…ä¸»å•é¡Œè·¨ç”¨æˆ¶å…±äº«
        key = self.generate_key(query, context, user_id)
        return self.planning_cache.get(key)

    def set_planning_cache(self, query: str, result: Any, context: str = "", user_id: str = ""):
        """
        è¨­ç½® Planning å¿«å–

        ğŸ”’ éš±ç§å„ªå…ˆç­–ç•¥ï¼š
        - ç¸½æ˜¯ä½¿ç”¨ user_id éš”é›¢ä¸åŒç”¨æˆ¶ï¼ˆé¿å…ä¸»å•é¡Œä¸­çš„å€‹äººä¿¡æ¯æ³„éœ²ï¼‰
        """
        if not self.planning_cache:
            return

        # ğŸ”’ å¼·åˆ¶åŒ…å« user_idï¼Œé¿å…ä¸»å•é¡Œè·¨ç”¨æˆ¶å…±äº«
        key = self.generate_key(query, context, user_id)
        self.planning_cache.set(key, result)

    def get_retrieval_cache(self, query: str, datasource_ids: list = None) -> Optional[Any]:
        """ç²å–æª¢ç´¢å¿«å–"""
        if not self.retrieval_cache:
            return None

        datasource_key = ",".join(sorted(datasource_ids)) if datasource_ids else "default"
        key = self.generate_key(query, datasource_key)
        return self.retrieval_cache.get(key)

    def set_retrieval_cache(self, query: str, result: Any, datasource_ids: list = None):
        """è¨­ç½®æª¢ç´¢å¿«å–"""
        if not self.retrieval_cache:
            return

        datasource_key = ",".join(sorted(datasource_ids)) if datasource_ids else "default"
        key = self.generate_key(query, datasource_key)
        self.retrieval_cache.set(key, result)

    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰å¿«å–"""
        if self.query_cache:
            self.query_cache.clear()
        if self.planning_cache:
            self.planning_cache.clear()
        if self.retrieval_cache:
            self.retrieval_cache.clear()
        print("ğŸ—‘ï¸ å·²æ¸…ç©ºæ‰€æœ‰å¿«å–")

    def get_stats(self) -> Dict[str, Any]:
        """ç²å–æ‰€æœ‰å¿«å–çµ±è¨ˆ"""
        stats = {}

        if self.query_cache:
            stats['query_cache'] = self.query_cache.get_stats()

        if self.planning_cache:
            stats['planning_cache'] = self.planning_cache.get_stats()

        if self.retrieval_cache:
            stats['retrieval_cache'] = self.retrieval_cache.get_stats()

        return stats

    def print_stats(self):
        """æ‰“å°å¿«å–çµ±è¨ˆ"""
        stats = self.get_stats()

        print("\n" + "="*60)
        print("ğŸ“Š å¿«å–çµ±è¨ˆ")
        print("="*60)

        for cache_name, cache_stats in stats.items():
            print(f"\nã€{cache_name}ã€‘")
            print(f"  å¤§å°: {cache_stats['size']}/{cache_stats['max_size']}")
            print(f"  å‘½ä¸­æ¬¡æ•¸: {cache_stats['hit_count']}")
            print(f"  æœªå‘½ä¸­æ¬¡æ•¸: {cache_stats['miss_count']}")
            print(f"  å‘½ä¸­ç‡: {cache_stats['hit_rate']:.2%}")
            print(f"  TTL: {cache_stats['ttl']}s")

        print("="*60 + "\n")


# ğŸ†• å…¨åŸŸå¿«å–ç®¡ç†å™¨å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰
_global_cache_manager = None

def get_cache_manager():
    """ç²å–å…¨åŸŸå”¯ä¸€çš„å¿«å–ç®¡ç†å™¨å¯¦ä¾‹"""
    global _global_cache_manager
    if _global_cache_manager is None:
        from core.config import CACHE_CONFIG
        if CACHE_CONFIG.get('enabled', True):
            _global_cache_manager = CacheManager(CACHE_CONFIG)
    return _global_cache_manager


# ===== è£é£¾å™¨ï¼šè‡ªå‹•å¿«å–å‡½æ•¸çµæœ =====

def cached_async(cache_manager: CacheManager, cache_type: str = "query"):
    """
    ç•°æ­¥å‡½æ•¸å¿«å–è£é£¾å™¨

    Args:
        cache_manager: CacheManager å¯¦ä¾‹
        cache_type: å¿«å–é¡å‹ ("query", "planning", "retrieval")
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆå¿«å–éµ
            cache_key = CacheManager.generate_key(*args, **kwargs)

            # å˜—è©¦å¾å¿«å–ç²å–
            cache = None
            if cache_type == "query":
                cache = cache_manager.query_cache
            elif cache_type == "planning":
                cache = cache_manager.planning_cache
            elif cache_type == "retrieval":
                cache = cache_manager.retrieval_cache

            if cache:
                cached_result = cache.get(cache_key)
                if cached_result is not None:
                    print(f"âœ… ä½¿ç”¨å¿«å–çµæœ ({cache_type}): {func.__name__}")
                    return cached_result

            # åŸ·è¡Œå‡½æ•¸
            result = await func(*args, **kwargs)

            # å­˜å…¥å¿«å–
            if cache:
                cache.set(cache_key, result)

            return result

        return wrapper
    return decorator


# ===== è¨˜æ†¶é«”ç®¡ç†å·¥å…· =====

class MemoryManager:
    """è¨˜æ†¶é«”ç®¡ç†å™¨ï¼ˆå°è©±æ­·å²ç®¡ç†ï¼‰"""

    def __init__(self, config: Dict[str, Any]):
        """
        Args:
            config: è¨˜æ†¶é«”ç®¡ç†é…ç½®
        """
        self.max_history_turns = config.get('max_history_turns', 50)
        self.keep_recent_turns = config.get('keep_recent_turns', 30)
        self.auto_cleanup = config.get('auto_cleanup', True)

        print(f"âœ… MemoryManager åˆå§‹åŒ–å®Œæˆ")
        print(f"   - æœ€å¤§æ­·å²è¼ªæ•¸: {self.max_history_turns}")
        print(f"   - ä¿ç•™æœ€è¿‘è¼ªæ•¸: {self.keep_recent_turns}")
        print(f"   - è‡ªå‹•æ¸…ç†: {self.auto_cleanup}")

    def should_cleanup(self, conversation_history: list) -> bool:
        """åˆ¤æ–·æ˜¯å¦éœ€è¦æ¸…ç†"""
        return self.auto_cleanup and len(conversation_history) > self.max_history_turns

    def cleanup(self, conversation_history: list) -> Tuple[list, int]:
        """
        æ¸…ç†å°è©±æ­·å²

        Returns:
            (æ¸…ç†å¾Œçš„æ­·å², æ¸…ç†çš„æ¢ç›®æ•¸)
        """
        if not self.should_cleanup(conversation_history):
            return conversation_history, 0

        original_len = len(conversation_history)
        cleaned = conversation_history[-self.keep_recent_turns:]
        removed = original_len - len(cleaned)

        print(f"ğŸ—‘ï¸ è‡ªå‹•æ¸…ç†å°è©±æ­·å²: ç§»é™¤ {removed} è¼ªï¼Œä¿ç•™æœ€è¿‘ {len(cleaned)} è¼ª")

        return cleaned, removed

    def get_memory_info(self, conversation_history: list) -> Dict[str, Any]:
        """ç²å–è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š"""
        import sys

        memory_bytes = sys.getsizeof(conversation_history)

        # è¨ˆç®—æ‰€æœ‰å°è©±å…§å®¹çš„å¤§å°
        for query, answer in conversation_history:
            memory_bytes += sys.getsizeof(query) + sys.getsizeof(answer)

        return {
            "turns": len(conversation_history),
            "max_turns": self.max_history_turns,
            "memory_bytes": memory_bytes,
            "memory_mb": memory_bytes / (1024 * 1024),
            "usage_percent": len(conversation_history) / self.max_history_turns * 100
        }

    def print_memory_info(self, conversation_history: list):
        """æ‰“å°è¨˜æ†¶é«”è³‡è¨Š"""
        info = self.get_memory_info(conversation_history)

        print(f"\nğŸ“Š å°è©±æ­·å²è¨˜æ†¶é«”è³‡è¨Š:")
        print(f"   -ç•¶å‰è¼ªæ•¸: {info['turns']}/{info['max_turns']}")
        print(f"   - è¨˜æ†¶é«”ä½¿ç”¨: {info['memory_mb']:.2f} MB")
        print(f"   - ä½¿ç”¨ç‡: {info['usage_percent']:.1f}%\n")