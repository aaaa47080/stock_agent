#!/usr/bin/env python3
"""
ğŸ¥ é†«ç™‚è¡›æ•™åœ–ç‰‡è‡ªå‹•åŒ–è™•ç†æµæ°´ç·š - å–®éšæ®µåš´æ ¼ç‰ˆ

æ”¹é€²é»ï¼š
1. æ•´åˆå…©éšæ®µæ¨™æº–åˆ°ä¸€å€‹åš´æ ¼çš„ Promptï¼Œçœæ™‚é–“
2. å¿…é ˆåŒæ™‚æ»¿è¶³ï¼šé†«ç™‚ç›¸é—œ + æœ‰å¯¦ç”¨è¡›æ•™åƒ¹å€¼ + æœ‰æ–‡å­—èªªæ˜
3. åš´æ ¼æ’é™¤ï¼šè£é£¾æ€§ã€å¡é€šã€ç´”å™¨å®˜åœ–ç¤ºã€ç„¡æ–‡å­—ç…§ç‰‡
4. æ‰¹æ¬¡è™•ç† + è¨˜æ†¶é«”å„ªåŒ– + æ–·é»çºŒå‚³
"""

import os
import sys
import json
import torch
import hashlib
import io
import re
import fitz
import asyncio
import logging
from pathlib import Path
from tqdm.asyncio import tqdm
from PIL import Image
from concurrent.futures import ThreadPoolExecutor
from transformers import AutoModelForVision2Seq, AutoProcessor
from langchain_core.documents import Document
from langchain_postgres.vectorstores import PGVector

PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from core.config import DB_CONNECTION_STRING, embeddings

# ==================== é…ç½® ====================
os.environ["CUDA_VISIBLE_DEVICES"] = "1"

TEMP_IMAGE_DIR = Path("/home/danny/AI-agent/image_search")
FINAL_IMAGE_DIR = Path("/home/danny/AI-agent/high_value_images")
PIPELINE_DATA_DIR = Path("/home/danny/AI-agent/pipeline_data")
MAPPING_JSON = PIPELINE_DATA_DIR / "image_source_mapping.json"
ANALYSIS_JSON = PIPELINE_DATA_DIR / "final_educational_analysis_strict.json"
PROCESSED_JSON = PIPELINE_DATA_DIR / "all_processed_images_strict.json"
VLM_MODEL_PATH = "/home/danny/AI-agent/Qwen3_4b_VL"

BATCH_SIZE = 2
MIN_SCORE = 4  # åš´æ ¼é–€æª»

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("StrictPipeline")

# ğŸ†• æ•´åˆå…©éšæ®µæ¨™æº–çš„åš´æ ¼ Prompt
STRICT_PROMPT = """è«‹åš´æ ¼è©•ä¼°é€™å¼µåœ–ç‰‡æ˜¯å¦ç‚ºã€Œé«˜å“è³ªé†«ç™‚è¡›æ•™å…§å®¹ï¼Œç—…äºº/æ°‘çœ¾å¯ä»¥ç›´æ¥çœ‹æ‡‚ä¸¦å¯¦éš›ä½¿ç”¨ã€ã€‚

**âœ“ å¿…é ˆåŒæ™‚æ»¿è¶³ä»¥ä¸‹æ‰€æœ‰æ¢ä»¶ï¼ˆè©•åˆ† 4-5ï¼‰ï¼š**

1. **é†«ç™‚ç›¸é—œæ€§**ï¼šåŒ…å«çœŸå¯¦çš„é†«ç™‚æˆ–å¥åº·æ•™è‚²å…§å®¹ï¼ˆç–¾ç—…ã€ç—‡ç‹€ã€æ²»ç™‚ã€é é˜²ã€æª¢æŸ¥ç­‰ï¼‰
2. **æœ‰æ–‡å­—èªªæ˜**ï¼šåœ–ç‰‡åŒ…å«æ¸…æ™°å¯è®€çš„æ–‡å­—èªªæ˜ã€æ¨™è¨»ã€æ­¥é©Ÿæˆ–æ•¸æ“š
3. **æ°‘çœ¾å¯çœ‹æ‡‚**ï¼šæ™®é€šäººä¸éœ€é†«å­¸èƒŒæ™¯å³å¯ç†è§£ä¸¦ä½¿ç”¨
4. **å¯¦ç”¨åƒ¹å€¼é«˜**ï¼šå±¬æ–¼ä»¥ä¸‹é¡å‹ä¹‹ä¸€
   - æ­¥é©ŸåŒ–æ“ä½œæŒ‡å°ï¼ˆå¦‚ï¼šæ´—æ‰‹æ­¥é©Ÿã€ç”¨è—¥æŒ‡å—ã€å‚·å£è™•ç†ï¼‰
   - ç—‡ç‹€å°ç…§åœ–ç¤ºï¼ˆå¦‚ï¼šçš®ç–¹åˆ†ç´šã€å§¿å‹¢æ­£èª¤å°æ¯”ï¼‰
   - æ•¸æ“šè¡¨æ ¼åœ–è¡¨ï¼ˆå¦‚ï¼šè¡€ç³–ç´€éŒ„è¡¨ã€ç”¨è—¥æ™‚é–“è¡¨ï¼‰
   - æª¢æŸ¥æµç¨‹åœ–ï¼ˆå¦‚ï¼šç¯©æª¢æµç¨‹ã€å°±é†«æ­¥é©Ÿï¼‰
   - æ³¨æ„äº‹é …åˆ—è¡¨ï¼ˆå¦‚ï¼šè¡“å¾Œç…§è­·ã€é£²é£Ÿç¦å¿Œï¼‰

**âœ— å¿…é ˆåš´æ ¼æ’é™¤ä»¥ä¸‹é¡å‹ï¼ˆè©•åˆ† 1-2ï¼‰ï¼š**

1. **è£é£¾æ€§åœ–ç‰‡**ï¼š
   - å¡é€šäººç‰©ã€å‰ç¥¥ç‰©ã€è¡¨æƒ…ç¬¦è™Ÿ
   - èƒŒæ™¯åœ–æ¡ˆã€é‚Šæ¡†è£é£¾ã€åˆ†éš”ç·š
   - ç´”ç¾åŒ–ç”¨é€”çš„æ’åœ–

2. **ç¼ºä¹æ–‡å­—èªªæ˜**ï¼š
   - æ²’æœ‰ä»»ä½•æ–‡å­—æ¨™è¨»çš„ç…§ç‰‡æˆ–æ’åœ–
   - å–®ç´”çš„å™¨å®˜åœ–ç¤ºã€è§£å‰–åœ–ï¼ˆæ²’æœ‰èªªæ˜æ–‡å­—ï¼‰
   - ç´”ç…§ç‰‡æ²’æœ‰æ¨™è¨»æˆ–è§£é‡‹

3. **å…§å®¹ä¸æ˜ç¢º**ï¼š
   - æ¨¡ç³Šä¸æ¸…ã€ç„¡æ³•é–±è®€çš„å…§å®¹
   - åªæœ‰æ¨™é¡Œæ²’æœ‰å…·é«”å…§å®¹çš„å°é¢é 
   - éæ–¼æŠ½è±¡ã€æ°‘çœ¾ç„¡æ³•ç†è§£çš„ç¤ºæ„åœ–
   - åªæœ‰è¨ºæ–·åç¨±æ²’æœ‰èªªæ˜çš„æ¨™é¡Œé 

4. **éå¯¦ç”¨æ€§å…§å®¹**ï¼š
   - ç´”ç²¹çš„é†«é™¢ä»‹ç´¹ã€ç§‘å®¤ç°¡ä»‹
   - é†«å¸«æˆ–è­·ç†äººå“¡çš„è‚–åƒç…§
   - é†«ç™‚è¨­å‚™çš„ç”¢å“ç…§ï¼ˆæ²’æœ‰ä½¿ç”¨èªªæ˜ï¼‰

**è¼¸å‡ºæ ¼å¼ï¼ˆå¿…é ˆæ˜¯æœ‰æ•ˆçš„ JSONï¼‰ï¼š**
{
  "is_health_related": true/false,
  "has_text_description": true/false,
  "is_self_explanatory": true/false,
  "is_decorative": true/false,
  "health_topic": "ä¸»é¡Œï¼ˆå¦‚ï¼šç³–å°¿ç—…ã€æ´—æ‰‹è¡›æ•™ã€ç”¨è—¥å®‰å…¨ï¼‰",
  "main_category": "åˆ†é¡ï¼ˆå¦‚ï¼šæ…¢æ€§ç—…ç®¡ç†/æ„ŸæŸ“æ§åˆ¶/ç”¨è—¥æŒ‡å°/æª¢æŸ¥æµç¨‹/è¡“å¾Œç…§è­·ï¼‰",
  "content_type": "æ­¥é©Ÿèªªæ˜/ç—‡ç‹€åœ–ç¤º/æ³¨æ„äº‹é …/æª¢æŸ¥æµç¨‹/æ•¸æ“šè¡¨æ ¼/è£é£¾æ€§/å°é¢é /å…¶ä»–",
  "core_message": "æ ¸å¿ƒè¨Šæ¯ï¼ˆ1å¥è©±ï¼‰",
  "detailed_description": "è©³ç´°æè¿°åœ–ç‰‡å…§å®¹å’Œè¡›æ•™é‡é»ï¼ˆ2-3å¥ï¼‰",
  "score": 1-5,
  "rejection_reason": "å¦‚æœè©•åˆ†<4ï¼Œèªªæ˜å…·é«”åŸå› ï¼ˆå¦‚ï¼šç¼ºä¹æ–‡å­—èªªæ˜/ç´”è£é£¾æ€§/å…§å®¹æ¨¡ç³Šï¼‰"
}

**è©•åˆ†æ¨™æº–ï¼š**
- 5åˆ†ï¼šå®Œç¾è¡›æ•™å…§å®¹ï¼Œæœ‰æ¸…æ™°æ–‡å­—+åœ–ç¤ºï¼Œæ°‘çœ¾å¯ç›´æ¥ä½¿ç”¨
- 4åˆ†ï¼šè‰¯å¥½è¡›æ•™å…§å®¹ï¼Œæœ‰æ–‡å­—èªªæ˜ï¼Œå…·å¯¦ç”¨åƒ¹å€¼
- 3åˆ†ï¼šæœ‰é†«ç™‚ç›¸é—œæ€§ï¼Œä½†ç¼ºä¹æ–‡å­—èªªæ˜æˆ–ä¸å¤ å¯¦ç”¨
- 2åˆ†ï¼šé†«ç™‚ç›¸é—œä½†ç„¡å¯¦ç”¨åƒ¹å€¼ï¼ˆå¦‚ï¼šå–®ç´”å™¨å®˜åœ–ã€å°é¢é ï¼‰
- 1åˆ†ï¼šè£é£¾æ€§åœ–ç‰‡æˆ–éé†«ç™‚å…§å®¹

åªè¼¸å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

class StrictHealthImagePipeline:
    def __init__(self):
        self.mapping = {}
        self.model = None
        self.processor = None
        for d in [TEMP_IMAGE_DIR, FINAL_IMAGE_DIR, PIPELINE_DATA_DIR]:
            d.mkdir(parents=True, exist_ok=True)
        if MAPPING_JSON.exists():
            self.mapping = json.loads(MAPPING_JSON.read_text(encoding='utf-8'))

    def load_vlm(self):
        if self.model is None:
            logger.info("æ­£åœ¨è¼‰å…¥ VLM æ¨¡å‹ä¸¦æº–å‚™æ‰¹æ¬¡æ¨ç†...")
            self.model = AutoModelForVision2Seq.from_pretrained(
                VLM_MODEL_PATH,
                torch_dtype=torch.bfloat16,
                attn_implementation="sdpa",
                device_map="auto",
                max_memory={0: "28GB"},
                low_cpu_mem_usage=True,
            ).eval()
            self.processor = AutoProcessor.from_pretrained(
                VLM_MODEL_PATH,
                min_pixels=256*28*28,
                max_pixels=512*28*28,
            )
            self.processor.tokenizer.padding_side = "left"

    # ---------- éšæ®µ 1: å¤šåŸ·è¡Œç·’æå– (å«å…¨åŸŸå»é‡) ----------

    def _extract_single_pdf(self, pdf_path: Path):
        local_extracted = []
        try:
            doc = fitz.open(pdf_path)
            for page_num in range(len(doc)):
                page = doc[page_num]
                for img_idx, img_info in enumerate(page.get_images(full=True), 1):
                    xref = img_info[0]
                    base_image = doc.extract_image(xref)
                    img_data = base_image["image"]
                    img_hash = hashlib.md5(img_data).hexdigest()
                    image = Image.open(io.BytesIO(img_data))
                    if image.width < 150 or image.height < 150: continue
                    filename = f"{pdf_path.stem}_p{page_num+1}_img{img_idx}.jpg"
                    local_extracted.append({
                        "hash": img_hash,
                        "filename": filename,
                        "data": img_data,
                        "source": {"source_pdf": pdf_path.name, "page": page_num + 1}
                    })
            doc.close()
        except Exception as e:
            logger.error(f"æå–å¤±æ•— {pdf_path.name}: {e}")
        return local_extracted

    async def step1_extract_async(self):
        logger.info("--- éšæ®µ 1: å¤šåŸ·è¡Œç·’æå–åœ–ç‰‡ (å«å…¨åŸŸæŒ‡ç´‹å»é‡) ---")
        pdf_files = list(Path("/home/danny/AI-agent/DataSet").rglob("*.pdf"))
        with ThreadPoolExecutor(max_workers=10) as executor:
            loop = asyncio.get_event_loop()
            tasks = [loop.run_in_executor(executor, self._extract_single_pdf, p) for p in pdf_files]
            all_raw_results = await tqdm.gather(*tasks, desc="ä¸¦è¡Œæå– PDF")

        seen_hashes = set()
        for info in self.mapping.values():
            if "hash" in info:
                seen_hashes.add(info["hash"])

        unique_count = 0
        for pdf_result in all_raw_results:
            for item in pdf_result:
                h = item["hash"]
                if h not in seen_hashes:
                    seen_hashes.add(h)
                    fname = item["filename"]
                    save_path = TEMP_IMAGE_DIR / fname
                    with open(save_path, "wb") as f:
                        f.write(item["data"])
                    item["source"]["hash"] = h
                    self.mapping[fname] = item["source"]
                    unique_count += 1

        MAPPING_JSON.write_text(json.dumps(self.mapping, ensure_ascii=False, indent=2))
        logger.info(f"âœ… æå–å®Œæˆï¼ç¶“æŒ‡ç´‹å»é‡å¾Œï¼Œæœ¬æ¬¡æ–°å¢ {unique_count} å¼µå”¯ä¸€åœ–ç‰‡ã€‚")

    # ---------- éšæ®µ 2 & 3: åš´æ ¼æ‰¹æ¬¡æ¨ç† ----------

    async def step2_3_strict_analyze(self):
        logger.info("--- éšæ®µ 2 & 3: åš´æ ¼ VLM åˆ†æï¼ˆæ•´åˆå…©éšæ®µæ¨™æº–ï¼‰---")
        self.load_vlm()

        image_files = sorted([f for f in TEMP_IMAGE_DIR.glob("*.jpg")])

        # è¼‰å…¥é«˜åˆ†çµæœ
        final_results = {}
        if ANALYSIS_JSON.exists():
            final_results = json.loads(ANALYSIS_JSON.read_text(encoding='utf-8')).get("educational_content", {})

        # è¼‰å…¥å·²è™•ç†åˆ—è¡¨
        processed_images = set()
        if PROCESSED_JSON.exists():
            processed_images = set(json.loads(PROCESSED_JSON.read_text(encoding='utf-8')).get("processed", []))

        to_process = [f for f in image_files if f.name not in processed_images]

        logger.info(f"åœ–ç‰‡ç¸½æ•¸: {len(image_files)} å¼µ")
        logger.info(f"å·²è™•ç†: {len(processed_images)} å¼µ")
        logger.info(f"å¾…è™•ç†: {len(to_process)} å¼µ, æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")

        if len(to_process) == 0:
            logger.info("âœ… æ‰€æœ‰åœ–ç‰‡å·²è™•ç†å®Œæˆï¼Œè·³éåˆ†æéšæ®µ")
            return

        pbar = tqdm(total=len(to_process), desc="åš´æ ¼ VLM åˆ†æ")

        for i in range(0, len(to_process), BATCH_SIZE):
            batch_files = to_process[i : i + BATCH_SIZE]
            batch_results, batch_processed = self._process_batch(batch_files)

            processed_images.update(batch_processed)
            self._save_processed_list(processed_images)

            if batch_results:
                final_results.update(batch_results)
                self._save_results(final_results)

            torch.cuda.empty_cache()
            pbar.update(len(batch_files))

        pbar.close()
        logger.info(f"âœ… åš´æ ¼åˆ†æå®Œæˆï¼é«˜å“è³ªåœ–ç‰‡: {len(final_results)} å¼µ")

    def _extract_topic_from_filename(self, filename: str) -> str:
        """å¾æª”æ¡ˆåç¨±æå–ä¸»é¡Œæç¤ºï¼ˆå»æ‰ _p1_img1.jpg ç­‰å¾Œç¶´ï¼‰"""
        # ç§»é™¤å‰¯æª”åå’Œé ç¢¼/åœ–ç‰‡ç·¨è™Ÿå¾Œç¶´
        topic = re.sub(r'_p\d+_i(mg)?\d+\.jpg$', '', filename, flags=re.IGNORECASE)
        # å°‡åº•ç·šæ›¿æ›ç‚ºç©ºæ ¼ï¼Œè®“æç¤ºæ›´è‡ªç„¶
        topic = topic.replace('_', ' ')
        return topic

    def _process_batch(self, batch_files):
        batch_results = {}
        batch_processed = set()
        batch_images = []
        inputs = None
        generated_ids = None

        try:
            batch_images = [Image.open(f) for f in batch_files]

            # ç‚ºæ¯å¼µåœ–ç‰‡å»ºç«‹å¸¶æœ‰æª”æ¡ˆåç¨±æç¤ºçš„ prompt
            messages_batch = []
            for idx, img in enumerate(batch_images):
                filename = batch_files[idx].name
                topic_hint = self._extract_topic_from_filename(filename)

                # å°‡æª”æ¡ˆåç¨±ä¸»é¡ŒåŠ å…¥ promptï¼Œå¹«åŠ© VLM ç”¢ç”Ÿæ›´ç²¾ç¢ºçš„æè¿°
                prompt_with_context = f"ã€åƒè€ƒè³‡è¨Šã€‘é€™å¼µåœ–ç‰‡ä¾†è‡ªè¡›æ•™æ–‡ä»¶ã€Œ{topic_hint}ã€ï¼Œè«‹åƒè€ƒæ­¤ä¸»é¡Œä¾†åˆ†æåœ–ç‰‡å…§å®¹ã€‚\n\n{STRICT_PROMPT}"

                messages_batch.append([{
                    "role": "user",
                    "content": [
                        {"type": "image", "image": img},
                        {"type": "text", "text": prompt_with_context}
                    ],
                }])

            batch_texts = [
                self.processor.apply_chat_template(m, tokenize=False, add_generation_prompt=True)
                for m in messages_batch
            ]
            del messages_batch

            inputs = self.processor(
                text=batch_texts,
                images=batch_images,
                return_tensors="pt",
                padding=True
            ).to(self.model.device)
            del batch_texts

            with torch.no_grad():
                generated_ids = self.model.generate(**inputs, max_new_tokens=500)

            # ä¿å­˜ input_ids é•·åº¦ä»¥ä¾¿å¾ŒçºŒ trim
            input_lengths = [len(ids) for ids in inputs.input_ids]

            del inputs
            inputs = None
            torch.cuda.empty_cache()

            generated_ids_cpu = generated_ids.cpu()
            del generated_ids
            generated_ids = None
            torch.cuda.empty_cache()

            # åªè§£ç¢¼æ–°ç”Ÿæˆçš„éƒ¨åˆ†ï¼ˆå»æ‰ promptï¼‰
            generated_ids_trimmed = [
                out_ids[input_len:] for out_ids, input_len in zip(generated_ids_cpu, input_lengths)
            ]
            output_texts = self.processor.batch_decode(
                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
            )
            del generated_ids_cpu, generated_ids_trimmed

            for idx, text_res in enumerate(output_texts):
                img_name = batch_files[idx].name
                batch_processed.add(img_name)

                json_res = self._parse_json(text_res)

                # ğŸ”§ åš´æ ¼éæ¿¾æ¢ä»¶ï¼š
                # 1. é†«ç™‚ç›¸é—œ (is_health_related = true)
                # 2. æœ‰æ–‡å­—èªªæ˜ (has_text_description = true)
                # 3. éè£é£¾æ€§ (is_decorative = false)
                # 4. é«˜åˆ† (score >= MIN_SCORE)
                if (json_res and
                    json_res.get("is_health_related") and
                    json_res.get("has_text_description") and
                    not json_res.get("is_decorative", False) and
                    json_res.get("score", 0) >= MIN_SCORE):

                    source = self.mapping.get(img_name, {})
                    json_res.update({
                        "source_pdf": source.get("source_pdf", "Unknown"),
                        "page": source.get("page", 0),
                        "filename": img_name
                    })
                    batch_results[img_name] = json_res

                    # æ­¸æª”é«˜å“è³ªåœ–ç‰‡
                    try:
                        img_to_save = batch_images[idx]
                        if img_to_save.mode != 'RGB':
                            img_to_save = img_to_save.convert('RGB')
                        img_to_save.save(FINAL_IMAGE_DIR / img_name, 'JPEG', quality=95)
                    except Exception as save_err:
                        logger.error(f"å­˜æª”å¤±æ•— {img_name}: {save_err}")

                    logger.info(f"âœ“ {img_name} (åˆ†æ•¸:{json_res.get('score')}) {json_res.get('content_type')}")
                else:
                    # è¨˜éŒ„æ‹’çµ•åŸå›  - é¡¯ç¤ºè©³ç´°çš„æª¢æŸ¥çµæœ
                    if json_res:
                        score = json_res.get("score", 0)
                        is_health = json_res.get("is_health_related", False)
                        has_text = json_res.get("has_text_description", False)
                        is_deco = json_res.get("is_decorative", False)
                        rejection = json_res.get("rejection_reason", "æœªé”æ¨™æº–")

                        logger.warning(
                            f"âœ— {img_name} - è©•åˆ†:{score} | "
                            f"é†«ç™‚ç›¸é—œ:{is_health} | æœ‰æ–‡å­—:{has_text} | "
                            f"è£é£¾æ€§:{is_deco} | åŸå› :{rejection}"
                        )
                    else:
                        logger.error(f"âœ— {img_name} - JSON è§£æå¤±æ•—")
                        logger.error(f"   VLM è¼¸å‡º: {text_res[:200]}...")

        except Exception as e:
            logger.error(f"æ‰¹æ¬¡è™•ç†å‡ºéŒ¯: {e}")
            import traceback
            logger.error(f"éŒ¯èª¤è©³æƒ…:\n{traceback.format_exc()}")
        finally:
            if inputs is not None:
                del inputs
            if generated_ids is not None:
                del generated_ids
            for img in batch_images:
                try: img.close()
                except: pass
            torch.cuda.empty_cache()

        return batch_results, batch_processed

    def _parse_json(self, text):
        try:
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                json_str = match.group(0)
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError as e:
                    logger.error(f"JSON è§£æéŒ¯èª¤: {e}")
                    logger.error(f"JSON å…§å®¹: {json_str[:300]}...")
                    return None
            else:
                logger.error(f"æœªæ‰¾åˆ° JSON æ ¼å¼")
                logger.error(f"VLM è¼¸å‡º: {text[:300]}...")
                return None
        except Exception as e:
            logger.error(f"_parse_json ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None

    def _save_results(self, results):
        ANALYSIS_JSON.write_text(json.dumps({"count": len(results), "educational_content": results}, ensure_ascii=False, indent=2))

    def _save_processed_list(self, processed_set):
        PROCESSED_JSON.write_text(json.dumps({"count": len(processed_set), "processed": sorted(list(processed_set))}, ensure_ascii=False, indent=2))

    # ---------- éšæ®µ 4: åŒæ­¥è³‡æ–™åº« ----------

    async def step4_sync_db_async(self, chunk_size: int = 500):
        logger.info("--- éšæ®µ 4: åˆ†æ‰¹æ¬¡å¯«å…¥å‘é‡è³‡æ–™åº« ---")
        if not ANALYSIS_JSON.exists():
            logger.warning("æ‰¾ä¸åˆ°åˆ†æçµæœï¼Œè·³éåŒæ­¥ã€‚")
            return

        data = json.loads(ANALYSIS_JSON.read_text(encoding='utf-8'))
        contents = data.get("educational_content", {})
        all_docs = []

        for filename, info in contents.items():
            page_content = f"ä¸»é¡Œ: {info.get('health_topic')}\nåˆ†é¡: {info.get('main_category')}\næ ¸å¿ƒè¨Šæ¯: {info.get('core_message')}\nè©³ç´°æè¿°: {info.get('detailed_description')}\nä¾†æºæ–‡ä»¶: {info.get('source_pdf')}"
            metadata = {
                "filename": filename,
                "image_path": filename,
                "health_topic": info.get("health_topic"),
                "main_category": info.get("main_category"),
                "content_type": info.get("content_type"),
                "has_text_description": info.get("has_text_description"),
                "is_self_explanatory": info.get("is_self_explanatory"),
                "source_pdf": info.get("source_pdf"),
                "page": info.get("page"),
                "score": info.get("score"),
                "source": "strict_pipeline"
            }
            all_docs.append(Document(page_content=page_content, metadata=metadata))

        if not all_docs:
            return

        logger.info(f"ç¸½å…±æº–å‚™äº† {len(all_docs)} ç­†è³‡æ–™ï¼Œå°‡ä»¥æ¯æ‰¹ {chunk_size} ç­†é€²è¡ŒåŒæ­¥...")

        try:
            # ğŸ”§ ä½¿ç”¨æµ‹è¯•é›†åˆåç§°ï¼Œé¿å…è¦†ç›–ç°æœ‰æ•°æ®
            # å¦‚æœæµ‹è¯•æ»¡æ„ï¼Œå¯ä»¥æ”¹ä¸º "educational_images"
            collection_name = "educational_images_strict_test"

            first_chunk = all_docs[:chunk_size]
            vector_store = PGVector.from_documents(
                documents=first_chunk,
                embedding=embeddings,
                connection=DB_CONNECTION_STRING,
                collection_name=collection_name,
                use_jsonb=True,
                pre_delete_collection=True
            )
            logger.info(f"âœ… å·²å®Œæˆç¬¬ä¸€æ‰¹æ¬¡ ({len(first_chunk)} ç­†) ä¸¦é‡è¨­è³‡æ–™åº«")

            for i in range(chunk_size, len(all_docs), chunk_size):
                chunk = all_docs[i : i + chunk_size]
                vector_store.add_documents(chunk)
                logger.info(f"âœ… å·²è¿½åŠ æ‰¹æ¬¡ {i//chunk_size + 1} ({i} ~ {min(i+chunk_size, len(all_docs))} ç­†)")

            logger.info(f"ğŸ‰ å…¨éƒ¨ {len(all_docs)} ç­†è³‡æ–™åŒæ­¥å®Œæˆï¼")
        except Exception as e:
            logger.error(f"è³‡æ–™åº«åˆ†æ‰¹å¯«å…¥å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()

async def main():
    pipeline = StrictHealthImagePipeline()
    await pipeline.step1_extract_async()
    await pipeline.step2_3_strict_analyze()  # åš´æ ¼å–®éšæ®µåˆ†æ
    await pipeline.step4_sync_db_async()
    logger.info("ğŸš€ æ‰€æœ‰ä»»å‹™è™•ç†å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())
