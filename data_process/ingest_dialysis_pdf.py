"""
æ›´æ–° PDF åˆ°è³‡æ–™åº« V2.1 (ä¿®å¾©ç‰ˆ)-è™•ç†æ´—è…ç§‘ç›¸é—œè³‡æ–™åº«

æ•´åˆæ”¹é€²ç‰ˆè¡¨æ ¼æ“·å–æ–¹æ³•ï¼š
- å…¨å¯¬åº¦è£åˆ‡ç­–ç•¥
- è‡ªå‹•åˆä½µé‡ç–Šè¡¨æ ¼
- æ”¯æ´è¡¨æ ¼ã€åœ–ç‰‡ã€åœ–è¡¨ç­‰å¤šç¨®ç‰©ä»¶é¡å‹
- ğŸ†• ä¿®å¾©ï¼šç´”åœ–ç‰‡/åœ–è¡¨å¼·åˆ¶å¯«å…¥å‘é‡ç´¢å¼•èˆ‡ Metadataï¼Œç¢ºä¿å¯è¢«æª¢ç´¢
"""
import os
import sys
from pathlib import Path
import tempfile
import time
import argparse
import gc
from io import StringIO, BytesIO

sys.path.append(str(Path(__file__).parent.parent))

from transformers import AutoModel, AutoTokenizer
import torch
import fitz
from PIL import Image
import re

from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_postgres import PGVector
from core.config import DB_HOST, DB_NAME, DB_PORT, DB_PASSWORD, DB_USER, embeddings


# ==================== é…ç½® ====================
os.environ["CUDA_VISIBLE_DEVICES"] = '0'
os.environ["CUDA_LAUNCH_BLOCKING"] = '1'

MODEL_PATH = '/home/danny/AI-agent/deepseek_ocr'
INPUT_DIR = '/home/danny/AI-agent/æ´—è…è¡›æ•™'
COLLECTION_NAME = "dialysis_education_materials"
db_connection = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# è¡¨æ ¼æ“·å–è¼¸å‡ºç›®éŒ„
from core.config import EXTRACTED_TABLES_DIR

# ==================== åƒæ•¸è¨­ç½® ====================
OCR_IMAGE_SIZE = 1024      # OCR è™•ç†å°ºå¯¸
HIGH_RES_DPI = 100         # é«˜è§£æåº¦è¡¨æ ¼è¼¸å‡º DPI
MIN_IMAGE_SIZE = 100       # æœ€å°åœ–ç‰‡å°ºå¯¸éæ¿¾
SKIP_FIRST_PAGE_IMAGES = False  # æ˜¯å¦è·³éç¬¬ä¸€é çš„åœ–ç‰‡

text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=1200,
    chunk_overlap=200
)


# ==================== GPU æ¸…ç† ====================
def cleanup_gpu():
    """æ¸…ç† GPU è¨˜æ†¶é«”"""
    gc.collect()
    torch.cuda.empty_cache()
    torch.cuda.synchronize()


# ==================== OCR è¼”åŠ©å‡½æ•¸ ====================

def capture_model_output():
    """æ•ç²æ¨¡å‹çš„æ¨™æº–è¼¸å‡º"""
    old_stdout = sys.stdout
    sys.stdout = captured_output = StringIO()
    return old_stdout, captured_output


def restore_stdout(old_stdout):
    """æ¢å¾©æ¨™æº–è¼¸å‡º"""
    sys.stdout = old_stdout


def extract_from_stdout(captured_text):
    """å¾æ•ç²çš„è¼¸å‡ºä¸­æå–è¡¨æ ¼æ¨™è¨˜"""
    start_marker = '<|ref|>'
    if start_marker not in captured_text:
        return None

    start_pos = captured_text.find(start_marker)
    end_marker = '===============save results:==============='
    end_pos = captured_text.find(end_marker)

    if end_pos == -1:
        relevant_text = captured_text[start_pos:]
    else:
        relevant_text = captured_text[start_pos:end_pos]

    return relevant_text.strip()


def extract_tables_and_images_from_result(result_text):
    """å¾ OCR çµæœä¸­æå–è¡¨æ ¼å’Œåœ–ç‰‡å€åŸŸ"""
    all_objects = []

    # é€šç”¨æ¨¡å¼:åŒ¹é… <|ref|>TYPE<|/ref|><|det|>[[x1, y1, x2, y2]]<|/det|>
    object_pattern = r'<\|ref\|>(\w+)<\|/ref\|><\|det\|>\[\[(\d+),\s*(\d+),\s*(\d+),\s*(\d+)\]\]<\|/det\|>'
    object_matches = re.findall(object_pattern, result_text)

    for match in object_matches:
        obj_type = match[0]
        x1, y1, x2, y2 = int(match[1]), int(match[2]), int(match[3]), int(match[4])

        # åªè™•ç†è¡¨æ ¼å’Œåœ–ç‰‡ç›¸é—œé¡å‹
        if obj_type in ['table', 'image', 'figure', 'chart', 'diagram']:
            obj_data = {
                'bbox': (x1, y1, x2, y2),
                'type': obj_type,
                'html': None
            }

            # å¦‚æœæ˜¯è¡¨æ ¼,å˜—è©¦æå– HTML
            if obj_type == 'table':
                search_str = f'[[{x1}, {y1}, {x2}, {y2}]]'
                search_start = result_text.find(search_str)
                if search_start != -1:
                    table_start = result_text.find('<table>', search_start)
                    if table_start != -1:
                        table_end = result_text.find('</table>', table_start)
                        if table_end != -1:
                            obj_data['html'] = result_text[table_start:table_end + 8]

            all_objects.append(obj_data)

    # æå–æ¨™é¡Œ(table_caption, figure_caption ç­‰)
    caption_pattern = r'<\|ref\|>(\w+_caption)<\|/ref\|><\|det\|>\[\[(\d+),\s*(\d+),\s*(\d+),\s*(\d+)\]\]<\|/det\|>\s*\n?(.*?)(?=\n\n|\n<\||$)'
    caption_matches = re.findall(caption_pattern, result_text, re.DOTALL)

    captions = []
    for match in caption_matches:
        captions.append({
            'bbox': (int(match[1]), int(match[2]), int(match[3]), int(match[4])),
            'text': match[5].strip(),
            'type': match[0]
        })

    return all_objects, captions


def calculate_bbox_overlap(bbox1, bbox2):
    """è¨ˆç®—å…©å€‹ bbox çš„é‡ç–Šæ¯”ä¾‹"""
    x1_1, y1_1, x2_1, y2_1 = bbox1
    x1_2, y1_2, x2_2, y2_2 = bbox2

    intersect_x1 = max(x1_1, x1_2)
    intersect_y1 = max(y1_1, y1_2)
    intersect_x2 = min(x2_1, x2_2)
    intersect_y2 = min(y2_1, y2_2)

    if intersect_x1 >= intersect_x2 or intersect_y1 >= intersect_y2:
        return 0.0

    intersect_area = (intersect_x2 - intersect_x1) * (intersect_y2 - intersect_y1)
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)

    smaller_area = min(area1, area2)
    return intersect_area / smaller_area if smaller_area > 0 else 0.0


def merge_overlapping_objects(objects_data, overlap_threshold=0.3):
    """åˆä½µé‡ç–Šçš„è¡¨æ ¼ç‰©ä»¶"""
    if not objects_data:
        return objects_data

    tables = [obj for obj in objects_data if obj['type'] == 'table']
    other_objects = [obj for obj in objects_data if obj['type'] != 'table']

    if len(tables) <= 1:
        return objects_data

    tables.sort(key=lambda obj: obj['bbox'][1])

    merged_tables = []
    skip_indices = set()

    for i, table1 in enumerate(tables):
        if i in skip_indices:
            continue

        bbox1 = table1['bbox']
        x1_1, y1_1, x2_1, y2_1 = bbox1

        for j in range(i + 1, len(tables)):
            if j in skip_indices:
                continue

            table2 = tables[j]
            bbox2 = table2['bbox']
            x1_2, y1_2, x2_2, y2_2 = bbox2

            y_overlap_start = max(y1_1, y1_2)
            y_overlap_end = min(y2_1, y2_2)
            y_overlap = max(0, y_overlap_end - y_overlap_start)

            height1 = y2_1 - y1_1
            height2 = y2_2 - y1_2
            smaller_height = min(height1, height2)

            vertical_overlap_ratio = y_overlap / smaller_height if smaller_height > 0 else 0
            horizontal_gap = min(abs(x2_1 - x1_2), abs(x2_2 - x1_1))

            if vertical_overlap_ratio > overlap_threshold and horizontal_gap < 100:
                merged_bbox = (
                    min(x1_1, x1_2),
                    min(y1_1, y1_2),
                    max(x2_1, x2_2),
                    max(y2_1, y2_2)
                )

                table1['bbox'] = merged_bbox
                skip_indices.add(j)

        merged_tables.append(table1)

    return merged_tables + other_objects


def find_related_caption(object_bbox, object_type, captions, max_distance=100):
    """å°‹æ‰¾ç‰©ä»¶å°æ‡‰çš„æ¨™é¡Œ"""
    object_y1 = object_bbox[1]
    best_caption = None
    min_distance = max_distance

    caption_type_map = {
        'table': 'table_caption',
        'figure': 'figure_caption',
        'image': 'figure_caption',
        'chart': 'figure_caption',
        'diagram': 'figure_caption',
    }
    target_caption_type = caption_type_map.get(object_type, f'{object_type}_caption')

    for caption in captions:
        if caption['type'] != target_caption_type:
            continue

        caption_y2 = caption['bbox'][3]
        if caption_y2 < object_y1:
            distance = object_y1 - caption_y2
            if distance < min_distance:
                min_distance = distance
                best_caption = caption['text']

    return best_caption


def is_references_section(text):
    """
    æª¢æ¸¬æ–‡æœ¬æ˜¯å¦ç‚ºåƒè€ƒæ–‡ç»å€å¡Š

    Returns:
        tuple: (is_references: bool, references_start_pos: int or None)
               å¦‚æœæ˜¯åƒè€ƒæ–‡ç»å€å¡Šï¼Œè¿”å› (True, é–‹å§‹ä½ç½®)
               å¦‚æœä¸æ˜¯ï¼Œè¿”å› (False, None)
    """
    if not text:
        return False, None

    # åƒè€ƒæ–‡ç»æ¨™é¡Œæ¨¡å¼
    ref_title_patterns = [
        r'(^|\n)\s*#{0,3}\s*åƒè€ƒæ–‡[ç»çŒ®]',
        r'(^|\n)\s*#{0,3}\s*References?\s*\n',
        r'(^|\n)\s*#{0,3}\s*åƒè€ƒè³‡æ–™',
        r'(^|\n)\s*#{0,3}\s*å¼•ç”¨æ–‡[ç»çŒ®]',
        r'(^|\n)\s*#{0,3}\s*Bibliography',
        r'(^|\n)\s*#{0,3}\s*æ–‡[ç»çŒ®]',
    ]

    for pattern in ref_title_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return True, match.start()

    # æª¢æ¸¬æ˜¯å¦æ•´é éƒ½æ˜¯å¼•ç”¨æ ¼å¼ï¼ˆæ²’æœ‰æ¨™é¡Œä½†å…§å®¹æ˜¯å¼•ç”¨ï¼‰
    lines = text.strip().split('\n')
    citation_count = 0
    total_lines = 0

    citation_patterns = [
        r'^\d+\.\s*[A-Z][a-z]+\s+[A-Z]{1,2}',  # 1. Smith AB...
        r'^\d+\.\s*[A-Z]{2,}[\.\s]',  # 1. WHO...
        r'^\[\d+\]',  # [1]
        r'J\s+(Clin\s+)?Endocrinol',  # Journal names
        r'\d{4}[;:]\d+[-â€“]\d+',  # å¹´ä»½;é ç¢¼ å¦‚ 2004;35:241-249
    ]

    for line in lines:
        line = line.strip()
        if len(line) < 5:
            continue
        total_lines += 1
        for pattern in citation_patterns:
            if re.search(pattern, line):
                citation_count += 1
                break

    # å¦‚æœè¶…é 60% çš„è¡Œæ˜¯å¼•ç”¨æ ¼å¼ï¼Œåˆ¤å®šç‚ºåƒè€ƒæ–‡ç»é 
    if total_lines > 5 and citation_count / total_lines > 0.6:
        return True, 0

    return False, None


def remove_references_section(text):
    """
    å¾æ–‡æœ¬ä¸­ç§»é™¤åƒè€ƒæ–‡ç»å€å¡Š

    Returns:
        str: ç§»é™¤åƒè€ƒæ–‡ç»å¾Œçš„æ–‡æœ¬
    """
    is_ref, start_pos = is_references_section(text)

    if is_ref and start_pos is not None:
        # å¦‚æœæ•´é éƒ½æ˜¯åƒè€ƒæ–‡ç»ï¼ˆstart_pos == 0ï¼‰ï¼Œè¿”å›ç©º
        if start_pos == 0:
            return ""
        # å¦å‰‡åªä¿ç•™åƒè€ƒæ–‡ç»ä¹‹å‰çš„å…§å®¹
        return text[:start_pos].strip()

    return text


def clean_ocr_output(text):
    """æ¸…ç† OCR è¼¸å‡º"""
    if not text:
        return ""

    text = re.sub(r'\\\(([^)]*)\\\)', r'\1', text)
    text = re.sub(r'\\mathrm\s*\{([^}]*)\}', r'\1', text)
    text = re.sub(r'\\text\s*\{([^}]*)\}', r'\1', text)
    text = re.sub(r'\\textbf\s*\{([^}]*)\}', r'\1', text)
    text = re.sub(r'\\sim', '~', text)
    text = re.sub(r'\\times', 'Ã—', text)
    text = re.sub(r'\\pm', 'Â±', text)
    text = re.sub(r'\\leq', 'â‰¤', text)
    text = re.sub(r'\\geq', 'â‰¥', text)

    greek_letters = {
        r'\\alpha': 'Î±', r'\\beta': 'Î²', r'\\gamma': 'Î³', r'\\delta': 'Î´',
        r'\\mu': 'Î¼', r'\\sigma': 'Ïƒ', r'\\omega': 'Ï‰', r'\\pi': 'Ï€',
    }
    for latex, char in greek_letters.items():
        text = re.sub(latex, char, text)
    text = re.sub(r'\\([a-zA-Z]+)', r'\1', text)

    text = re.sub(r'<sup>([^<]*)</sup>', r'^\1', text)
    text = re.sub(r'<sub>([^<]*)</sub>', r'_\1', text)

    # ç§»é™¤ HTML æ¨™ç±¤
    text = re.sub(r'<table>.*?</table>', '', text, flags=re.DOTALL)
    text = re.sub(r'<[^>]+>', '', text)

    text = re.sub(r'\n{3,}', '\n\n', text)
    text = re.sub(r' {2,}', ' ', text)

    # ğŸ†• ç§»é™¤åƒè€ƒæ–‡ç»å€å¡Š
    text = remove_references_section(text)

    return text.strip()


def extract_text_from_html_table(html_content):
    """å¾ HTML è¡¨æ ¼ä¸­æå–ç´”æ–‡å­—"""
    if not html_content:
        return ""

    import re
    from html import unescape

    text = re.sub(r'<br\s*/?>', ' ', html_content)
    text = re.sub(r'<sup>([^<]*)</sup>', r'^\1', text)
    text = re.sub(r'<sub>([^<]*)</sub>', r'_\1', text)
    text = re.sub(r'</tr>', '\n', text)
    text = re.sub(r'</td>|</th>', ' | ', text)
    text = re.sub(r'<[^>]+>', '', text)
    text = unescape(text)

    lines = [line.strip() for line in text.split('\n') if line.strip()]
    text = '\n'.join(lines)

    return text.strip()


def merge_short_pages(page_results, min_length=30):
    """å°‡å­—æ•¸éçŸ­çš„é é¢èˆ‡å‰å¾Œé é¢åˆä½µ"""
    if not page_results:
        return []

    merged = []
    i = 0
    while i < len(page_results):
        page_num, content = page_results[i]
        content_len = len(content.strip())

        if content_len >= min_length:
            merged.append((page_num, content))
            i += 1
            continue

        if i + 1 < len(page_results):
            next_page_num, next_content = page_results[i + 1]
            combined = f"{content}\n\n{next_content}"
            merged.append((page_num, combined))
            i += 2
        elif merged:
            prev_page_num, prev_content = merged[-1]
            combined = f"{prev_content}\n\n{content}"
            merged[-1] = (prev_page_num, combined)
            i += 1
        else:
            merged.append((page_num, content))
            i += 1
    return merged


# ==================== æ ¸å¿ƒ OCR èˆ‡è™•ç†é‚è¼¯ ====================

def ocr_pdf_by_page(model, tokenizer, pdf_path, selected_pages=None,
                     extract_tables=False, table_output_dir=None):
    """å°å–®å€‹ PDF é€²è¡Œ OCRï¼Œä¸¦è™•ç†è¡¨æ ¼/åœ–ç‰‡"""
    pdf_name = Path(pdf_path).stem
    print(f"\n{'='*70}")
    print(f"OCR: {pdf_name}.pdf")
    if extract_tables:
        print(f"ï¼ˆåŒæ™‚æ“·å–è¡¨æ ¼å’Œåœ–ç‰‡ï¼‰")
    print(f"{'='*70}")

    start_time = time.time()
    page_results = []
    tables_extracted = []

    # ğŸ†• ç‹€æ…‹è¿½è¸ªï¼šæ˜¯å¦å·²é€²å…¥åƒè€ƒæ–‡ç»å€å¡Š
    in_references_section = False

    try:
        doc = fitz.open(pdf_path)
        total_pages = len(doc)

        if selected_pages:
            valid_pages = [p for p in selected_pages if 1 <= p <= total_pages]
            pages_to_process = valid_pages
            print(f"å…± {total_pages} é ï¼Œé¸æ“‡è™•ç†: {pages_to_process}")
        else:
            pages_to_process = list(range(1, total_pages + 1))
            print(f"å…± {total_pages} é ")

        with tempfile.TemporaryDirectory() as tmp_dir:
            for page_num in pages_to_process:
                i = page_num - 1
                print(f"  ç¬¬ {page_num}/{total_pages} é ...", end=' ', flush=True)

                try:
                    page = doc[i]
                    page_width = page.rect.width
                    page_height = page.rect.height

                    # OCR é è¦½åœ–
                    ocr_scale = OCR_IMAGE_SIZE / max(page_width, page_height)
                    ocr_mat = fitz.Matrix(ocr_scale, ocr_scale)
                    ocr_pix = page.get_pixmap(matrix=ocr_mat)
                    ocr_width = ocr_pix.width
                    ocr_height = ocr_pix.height

                    img_path = os.path.join(tmp_dir, f"page_{page_num}.png")
                    ocr_pix.save(img_path)

                    result_file = os.path.join(tmp_dir, "result.mmd")
                    if os.path.exists(result_file):
                        os.remove(result_file)

                    # åŸ·è¡Œæ¨¡å‹
                    old_stdout, captured_output = capture_model_output()
                    model.infer(
                        tokenizer,
                        prompt="<image>\n<|grounding|>Convert the document to markdown.",
                        image_file=img_path,
                        output_path=tmp_dir,
                        base_size=OCR_IMAGE_SIZE,
                        image_size=OCR_IMAGE_SIZE,
                        crop_mode=False,
                        save_results=True,
                        test_compress=True
                    )
                    restore_stdout(old_stdout)
                    captured_text = captured_output.getvalue()

                    # è™•ç†æ–‡å­—
                    text_ok = False
                    page_text_content = ""

                    # ğŸ†• å¦‚æœå·²é€²å…¥åƒè€ƒæ–‡ç»å€å¡Šï¼Œè·³éå¾ŒçºŒé é¢çš„æ–‡å­—è™•ç†
                    if in_references_section:
                        print(f"â­ï¸ è·³éï¼ˆåƒè€ƒæ–‡ç»å€å¡Šï¼‰", end=' ', flush=True)
                    elif os.path.exists(result_file):
                        with open(result_file, 'r', encoding='utf-8') as f:
                            raw_text = f.read()

                            # ğŸ†• å…ˆæª¢æŸ¥æ˜¯å¦é€²å…¥åƒè€ƒæ–‡ç»å€å¡Šï¼ˆåœ¨æ¸…ç†ä¹‹å‰ï¼‰
                            is_ref, ref_start = is_references_section(raw_text)
                            if is_ref:
                                in_references_section = True
                                print(f"ğŸ“š æª¢æ¸¬åˆ°åƒè€ƒæ–‡ç»å€å¡Š", end=' ', flush=True)

                                # å¦‚æœåƒè€ƒæ–‡ç»å¾é é¢ä¸­é–“é–‹å§‹ï¼Œä¿ç•™ä¹‹å‰çš„å…§å®¹
                                if ref_start and ref_start > 0:
                                    partial_text = raw_text[:ref_start]
                                    cleaned = clean_ocr_output(partial_text)
                                    if cleaned.strip():
                                        page_text_content = cleaned
                                        text_ok = True
                                # å¦‚æœæ•´é éƒ½æ˜¯åƒè€ƒæ–‡ç»ï¼Œä¸è™•ç†
                            else:
                                cleaned = clean_ocr_output(raw_text)
                                if cleaned.strip():
                                    page_text_content = cleaned
                                    text_ok = True

                    # è™•ç†è¡¨æ ¼èˆ‡åœ–ç‰‡
                    object_count = 0
                    tables_text_content = []

                    # ğŸ†• å¦‚æœå·²é€²å…¥åƒè€ƒæ–‡ç»å€å¡Šï¼Œä¹Ÿè·³éè¡¨æ ¼è™•ç†
                    if extract_tables and table_output_dir and not in_references_section:
                        raw_result = extract_from_stdout(captured_text)
                        if raw_result:
                            objects_data, captions = extract_tables_and_images_from_result(raw_result)
                            
                            # åˆä½µé‡ç–Š
                            if objects_data:
                                objects_data = merge_overlapping_objects(objects_data, overlap_threshold=0.3)

                            if objects_data:
                                # ç”Ÿæˆé«˜è§£æåº¦åœ–ç‰‡
                                high_res_scale = HIGH_RES_DPI / 72.0
                                high_res_mat = fitz.Matrix(high_res_scale, high_res_scale)
                                high_res_pix = page.get_pixmap(matrix=high_res_mat)
                                high_res_width = high_res_pix.width
                                high_res_height = high_res_pix.height
                                high_res_img_data = high_res_pix.tobytes("png")
                                high_res_image = Image.open(BytesIO(high_res_img_data))
                                
                                scale_x = high_res_width / ocr_width
                                scale_y = high_res_height / ocr_height

                                for idx, obj in enumerate(objects_data, 1):
                                    bbox = obj['bbox']
                                    obj_type = obj['type']
                                    title = find_related_caption(bbox, obj_type, captions)

                                    if SKIP_FIRST_PAGE_IMAGES and page_num == 1 and obj_type != 'table':
                                        continue

                                    # åº§æ¨™æ›ç®—
                                    x1_hr = int(bbox[0] * scale_x)
                                    y1_hr = int(bbox[1] * scale_y)
                                    x2_hr = int(bbox[2] * scale_x)
                                    y2_hr = int(bbox[3] * scale_y)
                                    obj_width = x2_hr - x1_hr
                                    obj_height = y2_hr - y1_hr

                                    if obj_type != 'table':
                                        if obj_width < MIN_IMAGE_SIZE or obj_height < MIN_IMAGE_SIZE:
                                            continue

                                    # å…¨å¯¬åº¦è£åˆ‡
                                    x1_crop = 0
                                    x2_crop = high_res_width
                                    padding_top = max(int(obj_height * 0.25), 50)
                                    padding_bottom = max(int(obj_height * 0.25), 50)
                                    y1_crop = max(0, y1_hr - padding_top)
                                    y2_crop = min(high_res_height, y2_hr + padding_bottom)

                                    obj_img = high_res_image.crop((x1_crop, y1_crop, x2_crop, y2_crop))

                                    type_abbr = {'table': 't', 'image': 'i', 'figure': 'f', 'chart': 'c', 'diagram': 'd'}
                                    abbr = type_abbr.get(obj_type, 'o')

                                    # å„²å­˜åœ–ç‰‡
                                    jpg_path = os.path.join(table_output_dir, f"{pdf_name}_p{page_num}_{abbr}{idx}.jpg")
                                    obj_img.save(jpg_path, "JPEG", quality=95)
                                    jpg_filename = os.path.basename(jpg_path)

                                    # å˜—è©¦å°åœ–ç‰‡é€²è¡Œ OCR
                                    image_ocr_text = ""
                                    if obj_type in ['image', 'figure', 'chart', 'diagram']:
                                        try:
                                            import io as io_module
                                            old_img_stdout = sys.stdout
                                            sys.stdout = io_module.StringIO()
                                            model.infer(
                                                tokenizer,
                                                prompt="<image>\nExtract all text from this image.",
                                                image_file=jpg_path,
                                                output_path=tmp_dir,
                                                base_size=1024,
                                                image_size=1024,
                                                crop_mode=False,
                                                save_results=True,
                                                test_compress=False
                                            )
                                            sys.stdout = old_img_stdout
                                            
                                            result_files = [f for f in os.listdir(tmp_dir) if f.endswith('.mmd')]
                                            if result_files:
                                                latest_result = max([os.path.join(tmp_dir, f) for f in result_files], key=os.path.getmtime)
                                                with open(latest_result, 'r', encoding='utf-8') as rf:
                                                    image_ocr_text = clean_ocr_output(rf.read())
                                                os.remove(latest_result)
                                        except Exception:
                                            pass

                                    # æº–å‚™ HTML å’Œæ–‡å­—å…§å®¹
                                    html_path = os.path.join(table_output_dir, f"{pdf_name}_p{page_num}_{abbr}{idx}.html")
                                    
                                    ocr_text_content = ""
                                    if obj_type == 'table' and obj.get('html'):
                                        ocr_text_content = extract_text_from_html_table(obj['html'])
                                    elif image_ocr_text:
                                        ocr_text_content = image_ocr_text
                                    
                                    # ç¢ºä¿ HTML é¡¯ç¤º
                                    display_text = ocr_text_content if ocr_text_content else f"[{obj_type} content]"

                                    with open(html_path, 'w', encoding='utf-8') as f:
                                        if title: f.write(f"<h2>{title}</h2>\n")
                                        f.write(f'<div class="{obj_type}">\n')
                                        f.write(f'    <img src="{jpg_filename}" alt="{title or obj_type}" style="max-width: 100%;">\n')
                                        if ocr_text_content:
                                            f.write(f'    <p class="ocr-text">{ocr_text_content}</p>\n')
                                        f.write(f'</div>\n')

                                    # ğŸ†• æ§‹å»ºå‘é‡è³‡æ–™åº«ä½¿ç”¨çš„æ–‡å­—å€å¡Š
                                    # å¦‚æœæ²’æœ‰æ–‡å­—ï¼Œæˆ‘å€‘æ·»åŠ ä¸€å€‹ä½”ä½ç¬¦ï¼Œè®“è³‡æ–™åº«çŸ¥é“é€™è£¡æœ‰åœ–ç‰‡
                                    section_title = title if title else f"{obj_type} #{idx}"
                                    db_content_block = f"\n## {section_title}\n"
                                    
                                    if ocr_text_content and ocr_text_content != f"[{obj_type} content]":
                                        db_content_block += ocr_text_content
                                    else:
                                        # ğŸ†• å¼·åˆ¶å¯«å…¥ï¼šå¦‚æœæ²’æœ‰ OCR æ–‡å­—ï¼Œæ¨™è¨˜æœ‰åœ–ç‰‡æª”æ¡ˆ
                                        db_content_block += f"(æ­¤å€å¡ŠåŒ…å«åœ–ç‰‡/åœ–è¡¨è³‡æ–™ï¼Œè«‹åƒè€ƒé™„ä»¶: {jpg_filename})"
                                    
                                    tables_text_content.append(db_content_block)

                                    tables_extracted.append({
                                        'page': page_num,
                                        'table_idx': idx,
                                        'object_type': obj_type,
                                        'title': title,
                                        'jpg_path': jpg_path,
                                        'html_path': html_path
                                    })
                                    object_count += 1

                    # åˆä½µé é¢å…§å®¹
                    final_page_content = page_text_content
                    if tables_text_content:
                        final_page_content += "\n" + "\n".join(tables_text_content)

                    if final_page_content.strip():
                        page_results.append((page_num, final_page_content))
                        text_ok = True

                    if text_ok:
                        print(f"âœ“ ({len(final_page_content)}å­— + {object_count}ç‰©ä»¶)", flush=True)
                    else:
                        print("âš  ç„¡å…§å®¹", flush=True)

                    cleanup_gpu()

                except Exception as e:
                    print(f"âœ— éŒ¯èª¤: {e}", flush=True)
                    continue

        doc.close()

        if page_results:
            page_results = merge_short_pages(page_results, min_length=30)

        elapsed = time.time() - start_time
        print(f"âœ“ å®Œæˆï¼è€—æ™‚ {elapsed:.1f} ç§’")
        return page_results, tables_extracted

    except Exception as e:
        print(f"âœ— OCR å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return [], []


def process_single_pdf(model, tokenizer, vectorstore, pdf_path, extract_tables=True, target_pages=None):
    """è™•ç†å–®ä¸€ PDF ä¸¦æ·»åŠ åˆ°è³‡æ–™åº«"""
    pdf_path = Path(pdf_path)
    pdf_name = pdf_path.stem

    print(f"\n{'='*80}")
    print(f"ğŸ“„ è™•ç† PDF: {pdf_name}")
    print('='*80)

    table_output_dir = os.path.join(EXTRACTED_TABLES_DIR, pdf_name)
    page_table_map = {}

    if extract_tables:
        os.makedirs(table_output_dir, exist_ok=True)
        import glob
        old_files = glob.glob(os.path.join(table_output_dir, f"{pdf_name}_p*"))
        for f in old_files:
            os.remove(f)

    page_results, tables_extracted = ocr_pdf_by_page(
        model, tokenizer, str(pdf_path),
        selected_pages=target_pages,
        extract_tables=extract_tables,
        table_output_dir=table_output_dir if extract_tables else None
    )

    if not page_results:
        return 0, 0

    # å»ºç«‹æ˜ å°„
    total_objects = len(tables_extracted) if extract_tables else 0
    for table_info in tables_extracted:
        page_num = table_info['page']
        if page_num not in page_table_map:
            page_table_map[page_num] = []
        page_table_map[page_num].append(os.path.basename(table_info['jpg_path']))

    # å»ºç«‹æ–‡æª”
    pdf_documents = []
    for page_num, page_content in page_results:
        table_images = page_table_map.get(page_num, [])
        
        # ğŸ†• ä¿®æ­£ has_table åˆ¤æ–·ï¼šåªè¦æœ‰åœ–ç‰‡æˆ–è¡¨æ ¼æ–‡å­—éƒ½ç®— True
        has_table = (len(table_images) > 0) or ('<table>' in page_content or '|' in page_content)

        doc = Document(
            page_content=page_content,
            metadata={
                'source_file': pdf_path.name,
                'source_type': 'ocr_pdf',
                'page': page_num,
                'original_text': page_content,
                'category': 'æ´—è…è¡›æ•™',
                'title': '',
                'keywords': '',
                'reference': pdf_path.name,
                'collection_name': COLLECTION_NAME,
                'sheet_name': '',
                'folder': '',
                'page_label': str(page_num),
                'has_table': has_table,
                'table_images': table_images,
            }
        )
        pdf_documents.append(doc)

    print(f"\n  âœ… å»ºç«‹ {len(page_results)} å€‹é é¢æ–‡æª”")
    print(f"  åˆ†å‰²ä¸¦å¯«å…¥è³‡æ–™åº«...", end=' ')
    
    split_docs = text_splitter.split_documents(pdf_documents)
    
    try:
        vectorstore.add_documents(split_docs)
        print(f"âœ“ å·²æ·»åŠ  {len(split_docs)} å€‹ç‰‡æ®µ")
        return len(split_docs), total_objects
    except Exception as e:
        print(f"âœ— æ·»åŠ å¤±æ•—: {e}")
        return 0, total_objects


def parse_pages(pages_str):
    if not pages_str: return None
    pages = set()
    for part in pages_str.split(','):
        part = part.strip()
        if '-' in part:
            start, end = part.split('-', 1)
            pages.update(range(int(start), int(end) + 1))
        else:
            pages.add(int(part))
    return sorted(pages)


def main():
    parser = argparse.ArgumentParser(description='æ›´æ–° PDF åˆ°è³‡æ–™åº« V2.1 (ä¿®å¾©ç‰ˆ)')
    parser.add_argument('--file', type=str, help='æŒ‡å®šå–®ä¸€ PDF æª”æ¡ˆ')
    parser.add_argument('--all', action='store_true', help='è™•ç†æ‰€æœ‰ PDF æª”æ¡ˆ')
    parser.add_argument('--no-extract', action='store_true', help='ä¸æ“·å–è¡¨æ ¼')
    parser.add_argument('--pages', type=str, help='æŒ‡å®šé é¢ç¯„åœ (ä¾‹å¦‚: 1,3,5-10)')
    parser.add_argument('--dry-run', action='store_true', help='ä¸å¯«å…¥è³‡æ–™åº«')

    args = parser.parse_args()

    if not args.file and not args.all:
        parser.print_help()
        return

    target_pages = parse_pages(args.pages) if args.pages else None

    # è¼‰å…¥æ¨¡å‹
    print("\nğŸ“¥ è¼‰å…¥ OCR æ¨¡å‹...")
    try:
        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
        model = AutoModel.from_pretrained(
            MODEL_PATH,
            trust_remote_code=True,
            use_safetensors=True,
            torch_dtype=torch.bfloat16
        ).eval().cuda()
        print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return

    # é€£æ¥è³‡æ–™åº«
    vectorstore = None
    if not args.dry_run:
        print("\nğŸ“¦ é€£æ¥è³‡æ–™åº«...")
        try:
            vectorstore = PGVector(
                embeddings=embeddings,
                connection=db_connection,
                collection_name=COLLECTION_NAME,
            )
            print(f"âœ… å·²é€£æ¥ {COLLECTION_NAME}")
        except Exception as e:
            print(f"âŒ é€£æ¥å¤±æ•—: {e}")
            return

        # åˆªé™¤èˆŠè³‡æ–™ (å–®ä¸€æª”æ¡ˆæ¨¡å¼)
        if args.file:
            pdf_name = Path(args.file).name
            print(f"\n  åˆªé™¤ '{pdf_name}' çš„èˆŠè³‡æ–™...")
            try:
                from sqlalchemy import create_engine, text
                engine = create_engine(db_connection)
                with engine.connect() as conn:
                    result = conn.execute(
                        text("""
                            DELETE FROM langchain_pg_embedding
                            WHERE cmetadata->>'source_file' = :filename
                            AND collection_id = (
                                SELECT uuid FROM langchain_pg_collection
                                WHERE name = :collection_name
                            )
                        """),
                        {"filename": pdf_name, "collection_name": COLLECTION_NAME}
                    )
                    conn.commit()
            except Exception as e:
                print(f"  âš  åˆªé™¤å¤±æ•—: {e}")

    # åŸ·è¡Œè™•ç†
    if args.file:
        pdf_path = Path(args.file)
        if not pdf_path.exists():
            print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {pdf_path}")
            return

        chunks, tables = process_single_pdf(
            model, tokenizer, vectorstore, pdf_path,
            extract_tables=not args.no_extract,
            target_pages=target_pages
        )

    elif args.all:
        print("\nâš ï¸  å°‡æ¸…é™¤èˆŠè³‡æ–™ä¸¦é‡æ–°è™•ç†å…¨éƒ¨ PDF")
        confirm = input("ç¢ºå®šè¦ç¹¼çºŒå—ï¼Ÿ(y/N): ").strip().lower()
        if confirm != 'y': return

        pdf_files = sorted(Path(INPUT_DIR).glob("*.pdf"))
        
        for i, pdf_path in enumerate(pdf_files, 1):
            print(f"\n[{i}/{len(pdf_files)}] è™•ç†: {pdf_path.name}")
            
            pdf_name = pdf_path.stem
            table_output_dir = None
            if not args.no_extract:
                table_output_dir = os.path.join(EXTRACTED_TABLES_DIR, pdf_name)
                os.makedirs(table_output_dir, exist_ok=True)
                import glob
                old_files = glob.glob(os.path.join(table_output_dir, f"{pdf_name}_p*"))
                for f in old_files: os.remove(f)

            page_results, tables_extracted = ocr_pdf_by_page(
                model, tokenizer, str(pdf_path),
                extract_tables=not args.no_extract,
                table_output_dir=table_output_dir
            )

            if not page_results: continue

            # å»ºç«‹æ˜ å°„
            page_table_map = {}
            for table_info in tables_extracted:
                page_num = table_info['page']
                if page_num not in page_table_map:
                    page_table_map[page_num] = []
                page_table_map[page_num].append(os.path.basename(table_info['jpg_path']))

            # å»ºç«‹æ–‡æª”
            pdf_documents = []
            for page_num, page_content in page_results:
                table_images = page_table_map.get(page_num, [])
                
                # ğŸ†• æ‰¹æ¬¡è™•ç†åŒæ¨£ä¿®æ­£ has_table åˆ¤æ–·
                has_table = (len(table_images) > 0) or ('<table>' in page_content or '|' in page_content)

                doc = Document(
                    page_content=page_content,
                    metadata={
                        'source_file': pdf_path.name,
                        'source_type': 'ocr_pdf',
                        'page': page_num,
                        'original_text': page_content,
                        'category': 'æ´—è…è¡›æ•™',
                        'title': '',
                        'keywords': '',
                        'reference': pdf_path.name,
                        'collection_name': COLLECTION_NAME,
                        'sheet_name': '',
                        'folder': '',
                        'page_label': str(page_num),
                        'has_table': has_table,
                        'table_images': table_images,
                    }
                )
                pdf_documents.append(doc)

            split_docs = text_splitter.split_documents(pdf_documents)

            if i == 1:
                vectorstore = PGVector.from_documents(
                    documents=split_docs,
                    embedding=embeddings,
                    connection=db_connection,
                    collection_name=COLLECTION_NAME,
                    pre_delete_collection=True,
                )
            else:
                vectorstore.add_documents(split_docs)
            
            print(f"  âœ“ å·²æ·»åŠ  {len(split_docs)} å€‹ç‰‡æ®µ")
            cleanup_gpu()

if __name__ == "__main__":
    main()