import sys
import os
# Add the project root directory to the Python path to allow imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
from datetime import datetime
from typing import List, Optional
from data.data_fetcher import get_data_fetcher, SymbolNotFoundError
from data.indicator_calculator import add_technical_indicators
from data.data_processor import (
    calculate_key_levels,
    analyze_market_structure,
    extract_technical_indicators,
    calculate_price_info,
)

def analyze_symbol_data(df: pd.DataFrame, symbol: str) -> dict:
    """Analyzes a single symbol's dataframe and returns a dictionary of results."""
    if df is None or df.empty:
        return None

    # Add technical indicators
    df_with_indicators = add_technical_indicators(df)
    latest_data = df_with_indicators.iloc[-1]

    # Perform analysis
    analysis = {
        "symbol": symbol,
        "price_info": calculate_price_info(df_with_indicators),
        "technical_indicators": extract_technical_indicators(latest_data),
        "market_structure": analyze_market_structure(df_with_indicators),
        "key_levels": calculate_key_levels(df_with_indicators),
    }
    return analysis

def screen_top_cryptos(exchange='okx', limit=30, interval='1d', target_symbols: Optional[List[str]] = None):
    """
    Fetches, analyzes, and ranks cryptocurrencies.
    
    Args:
        exchange: Exchange name
        limit: Max number of symbols if scanning top market cap
        interval: Timeframe
        target_symbols: Optional list of symbols to analyze exclusively. 
                        If provided, 'limit' is ignored for fetching.
    """
    print(f"Starting crypto screening process for {exchange.upper()}...")

    # 1. Initialize data fetcher
    try:
        fetcher = get_data_fetcher(exchange)
    except ValueError as e:
        print(f"Error: {e}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    # 2. Get symbols list
    if target_symbols and len(target_symbols) > 0:
        print(f"Using target list: {target_symbols}")
        # Normalize symbols for the fetcher if needed (simple append)
        # Note: data_fetcher usually expects "BTC" or "BTC-USDT" depending on exchange.
        # Here we assume the input is cleaner "BTC" and fetcher handles suffix, 
        # OR we handle suffix here. Let's try to be smart.
        top_symbols = []
        for s in target_symbols:
            s_clean = s.upper().replace("USDT", "").replace("-", "")
            if exchange == 'okx':
                top_symbols.append(f"{s_clean}-USDT")
            else:
                top_symbols.append(f"{s_clean}USDT")
    else:
        top_symbols = fetcher.get_top_symbols(limit=limit)
        
    if not top_symbols:
        print("Could not retrieve symbols. Exiting.")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    # 3. Fetch and analyze data for each symbol
    all_analysis_results = []
    all_raw_data = []

    import concurrent.futures

    def process_symbol(symbol):
        """Helper function to fetch and analyze a single symbol."""
        try:
            # print(f"Fetching and analyzing data for {symbol}...")
            klines_df = fetcher.get_historical_klines(symbol, interval, limit=100)
            if klines_df is not None:
                # Store raw data
                klines_df_copy = klines_df.copy()
                klines_df_copy['symbol'] = symbol
                
                # Perform analysis
                analysis_result = analyze_symbol_data(klines_df, symbol)
                return klines_df_copy, analysis_result
            else:
                print(f"No data returned for {symbol}.")
                return None, None
        except SymbolNotFoundError:
            print(f"Symbol {symbol} not found or not supported. Skipping.")
            return None, None
        except Exception as e:
            print(f"An unexpected error occurred for {symbol}: {e}")
            return None, None

    # Use ThreadPoolExecutor for parallel execution
    # Determine max workers (reduced to prevent rate limiting/IP bans)
    max_workers = min(len(top_symbols), 3) 
    print(f"Starting parallel analysis with {max_workers} workers...")

    import time
    import random

    def process_symbol_with_delay(symbol):
        # Add random delay to distribute requests and avoid hitting rate limits
        time.sleep(random.uniform(0.5, 2.0)) 
        return process_symbol(symbol)

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_symbol = {executor.submit(process_symbol_with_delay, symbol): symbol for symbol in top_symbols}
        
        # Process results as they complete
        for future in concurrent.futures.as_completed(future_to_symbol):
            symbol = future_to_symbol[future]
            try:
                raw_data, analysis_result = future.result()
                if raw_data is not None:
                    all_raw_data.append(raw_data)
                if analysis_result:
                    all_analysis_results.append(analysis_result)
            except Exception as exc:
                print(f'{symbol} generated an exception: {exc}')

    if not all_analysis_results:
        print("No analysis was performed. Exiting.")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    # 4. Create a summary DataFrame for ranking
    summary_list = []
    for result in all_analysis_results:
        # Avoid potential None values in price info
        price_info = result["price_info"] or {}
        market_structure = result["market_structure"] or {}
        tech_indicators = result["technical_indicators"] or {}
        key_levels = result["key_levels"] or {}
        
        # --- è¨Šè™Ÿåµæ¸¬é‚è¼¯ ---
        signals = []
        
        # 1. é»ƒé‡‘äº¤å‰ (MA7 > MA25)
        ma7 = tech_indicators.get("MA_7", 0)
        ma25 = tech_indicators.get("MA_25", 0)
        # ç°¡å–®åˆ¤å®šï¼šå¦‚æžœ MA7 > MA25 ä¸”å·®è·ä¸å¤§ï¼ˆå‰›äº¤å‰ä¸ä¹…ï¼‰ï¼Œæˆ–è€…æˆ‘å€‘éœ€è¦æ›´ç²¾ç¢ºçš„äº¤å‰åˆ¤å®šï¼ˆéœ€è¦å‰ä¸€æ ¹ K ç·šï¼‰
        # é€™è£¡ç°¡åŒ–ç‚ºï¼šåªè¦ MA7 > MA25 å°±æ¨™ç¤ºç‚ºå¤šé ­æŽ’åˆ—ï¼Œè‹¥é…åˆå…¶ä»–æŒ‡æ¨™æ›´å¼·
        if ma7 > ma25:
            # é€™è£¡å¯ä»¥é€²ä¸€æ­¥åˆ¤æ–·ä¹–é›¢çŽ‡ï¼Œé¿å…å·²ç¶“æ¼²å¤ªå¤šçš„
            pass 
            
        # 2. æµ·é¾œçªç ´ (åƒ¹æ ¼ > 20æ—¥é«˜é»ž)
        current_price = price_info.get("ç•¶å‰åƒ¹æ ¼", 0)
        high_20d = key_levels.get("20æ—¥æœ€é«˜åƒ¹", 9999999)
        if current_price > high_20d:
            signals.append("ðŸ¢çªç ´")
            
        # 3. çˆ†é‡ (Volume Spike)
        if market_structure.get("çˆ†é‡", False):
            signals.append("ðŸ”¥çˆ†é‡")
            
        # 4. é»ƒé‡‘äº¤å‰ (EMA 7/25 or similar) - é€™è£¡ç”¨ MA ä»£æ›¿
        # ç‚ºäº†æ›´ç²¾ç¢ºï¼Œæˆ‘å€‘å‡è¨­ current_price > MA7 > MA25 ä¸” RSI < 70 (æœªéŽç†±)
        if ma7 > ma25 and tech_indicators.get("RSI_14", 50) < 70:
            # å¦‚æžœåªæ˜¯å–®ç´”å¤šé ­æŽ’åˆ—ï¼Œçµ¦å€‹å°æ˜Ÿæ˜Ÿï¼›å¦‚æžœæ˜¯å‰›äº¤å‰ï¼ˆæ¯”è¼ƒé›£åˆ¤æ–·ï¼‰ï¼Œå…ˆçµ¦é‡‘å‰æ¨™ç±¤
            # é€™è£¡ç°¡åŒ–ï¼šå¤šé ­æŽ’åˆ—ä¸”å¼·å‹¢
            signals.append("âœ¨é‡‘å‰")

        # 5. æŠ„åº• (RSI < 30)
        if tech_indicators.get("RSI_14", 50) < 30:
            signals.append("ðŸ’ŽæŠ„åº•")

        summary_item = {
            "Symbol": result["symbol"],
            "Current Price": price_info.get("ç•¶å‰åƒ¹æ ¼", 0),
            "24h Change %": price_info.get("24å°æ™‚åƒ¹æ ¼è®ŠåŒ–ç™¾åˆ†æ¯”", 0),
            "7d Change %": price_info.get("7å¤©åƒ¹æ ¼è®ŠåŒ–ç™¾åˆ†æ¯”", 0),
            "Trend": market_structure.get("è¶¨å‹¢", "Unknown"),
            "Volatility": market_structure.get("æ³¢å‹•çŽ‡", 0),
            "RSI_14": tech_indicators.get("RSI_14", 50),
            "Support": key_levels.get("æ”¯æ’ä½", 0),
            "Resistance": key_levels.get("å£“åŠ›ä½", 0),
            "Signals": signals  # æ–°å¢žè¨Šè™Ÿæ¬„ä½
        }
        summary_list.append(summary_item)
    
    summary_df = pd.DataFrame(summary_list)

    # 5. [Removed] Save raw data and summary report (Logic removed to keep directory clean)
    # The output_dir logic and CSV saving has been disabled.
    
    # 6. Prepare DataFrames for output
    # Ensure columns are numeric for sorting
    summary_df["24h Change %"] = pd.to_numeric(summary_df["24h Change %"], errors='coerce').fillna(0)
    summary_df["7d Change %"] = pd.to_numeric(summary_df["7d Change %"], errors='coerce').fillna(0)
    summary_df["RSI_14"] = pd.to_numeric(summary_df["RSI_14"], errors='coerce').fillna(50)

    top_performers = summary_df.sort_values(by="24h Change %", ascending=False).head(10)
    oversold = summary_df[summary_df["RSI_14"] < 40].sort_values(by="RSI_14", ascending=True).head(10)
    overbought = summary_df[summary_df["RSI_14"] > 70].sort_values(by="RSI_14", ascending=False).head(10)

    return summary_df, top_performers, oversold, overbought


if __name__ == '__main__':
    # You can choose 'binance' or 'okx'
    screen_top_cryptos(exchange='binance', limit=30, interval='1d')