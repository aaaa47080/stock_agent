import asyncio
from typing import Optional
from fastapi import APIRouter, HTTPException, Header

from core.config import SUPPORTED_EXCHANGES
from data.market_data import get_klines
from trading.okx_api_connector import OKXAPIConnector
from api.models import KlineRequest, ScreenerRequest, RefreshPulseRequest
from api.utils import logger
from api.globals import (
    cached_screener_result,
    FUNDING_RATE_CACHE,
    MARKET_PULSE_CACHE,
    screener_lock,
    get_symbol_lock,
    ANALYSIS_STATUS
)
from api.services import (
    save_screener_cache,
    save_market_pulse_cache,
    update_funding_rates,
    refresh_all_market_pulse_data
)
from analysis.crypto_screener import screen_top_cryptos
from analysis.market_pulse import get_market_pulse
import numpy as np
from datetime import datetime

router = APIRouter()

@router.get("/api/market/symbols")
async def get_market_symbols(exchange: str = "binance"):
    """Get all available symbols for a given exchange."""
    logger.info(f"Requesting symbol list for exchange: {exchange}")
    try:
        from data.data_fetcher import get_data_fetcher
        fetcher = get_data_fetcher(exchange)
        symbols = fetcher.get_all_symbols()
        logger.info(f"Successfully fetched {len(symbols)} symbols from {exchange}")
        return {"symbols": symbols}
    except Exception as e:
        logger.error(f"Failed to fetch symbols from {exchange}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/api/screener")
async def run_screener(request: ScreenerRequest):
    """å›å‚³å¸‚å ´ç¯©é¸æ•¸æ“š (å„ªå…ˆä½¿ç”¨å¿«å–ï¼Œä¸¦æ”¯æ´ç­‰å¾…èƒŒæ™¯ä»»å‹™)"""
    
    # 1. è‡ªå®šç¾©è«‹æ±‚ï¼šç›´æ¥åŸ·è¡Œ
    if request.symbols and len(request.symbols) > 0:
        logger.info(f"åŸ·è¡Œè‡ªå®šç¾©å¸‚å ´ç¯©é¸: {request.exchange}, Symbols: {len(request.symbols)}")
        try:
             loop = asyncio.get_running_loop()
             summary_df, top_performers, oversold, overbought = await loop.run_in_executor(
                None, 
                lambda: screen_top_cryptos(
                    exchange=request.exchange, 
                    limit=len(request.symbols), 
                    interval="1d",
                    target_symbols=request.symbols
                )
            )
             # ... formatting ...
             rename_map = {
                "Current Price": "Close", 
                "24h Change %": "price_change_24h", 
                "7d Change %": "price_change_7d", "Signals": "signals"
            }
             top_performers = top_performers.rename(columns=rename_map).replace({np.nan: None})
             oversold = oversold.rename(columns=rename_map).replace({np.nan: None})
             overbought = overbought.rename(columns=rename_map).replace({np.nan: None})
             return {
                "top_performers": top_performers.to_dict(orient="records"),
                "oversold": oversold.to_dict(orient="records"),
                "overbought": overbought.to_dict(orient="records"),
                "last_updated": datetime.now().isoformat()
            }
        except Exception as e:
             logger.error(f"è‡ªå®šç¾©ç¯©é¸å¤±æ•—: {e}", exc_info=True)
             raise HTTPException(status_code=500, detail=str(e))

    # 2. æª¢æŸ¥å¿«å–
    if cached_screener_result["data"] is not None:
        return cached_screener_result["data"]
    
    # 3. è‹¥å¿«å–ç‚ºç©ºï¼Œæª¢æŸ¥æ˜¯å¦èƒŒæ™¯ä»»å‹™æ­£åœ¨é‹è¡Œ
    if screener_lock.locked():
        logger.info("Cache empty, waiting for background analysis to complete...")
        async with screener_lock:
             # ç­‰å¾…é–é‡‹æ”¾å¾Œï¼Œå†æ¬¡æª¢æŸ¥å¿«å–
             if cached_screener_result["data"] is not None:
                 return cached_screener_result["data"]

    # 4. è‹¥ç­‰å¾…å¾Œä»ç„¡æ•¸æ“šï¼ˆæ¥µå°‘è¦‹ï¼‰ï¼Œæˆ–æœªé–å®šï¼Œå‰‡åŸ·è¡ŒåŒæ­¥æ›´æ–° (Double-check Locking)
    # ä½¿ç”¨é–é˜²æ­¢å¤šå€‹è«‹æ±‚åŒæ™‚è§¸ç™¼
    async with screener_lock:
        if cached_screener_result["data"] is not None:
            return cached_screener_result["data"]
            
        logger.info(f"ç„¡å¿«å–ä¸”ç„¡èƒŒæ™¯ä»»å‹™ï¼ŒåŸ·è¡Œå³æ™‚å¸‚å ´ç¯©é¸: {request.exchange}")
        try:
            loop = asyncio.get_running_loop()
            summary_df, top_performers, oversold, overbought = await loop.run_in_executor(
                None, 
                lambda: screen_top_cryptos(
                    exchange=request.exchange, 
                    limit=10, 
                    interval="1d",
                    target_symbols=None
                )
            )
            # ... formatting ...
            rename_map = {
                "Current Price": "Close", "24h Change %": "price_change_24h", 
                "7d Change %": "price_change_7d", "Signals": "signals"
            }
            top_performers = top_performers.rename(columns=rename_map).replace({np.nan: None})
            oversold = oversold.rename(columns=rename_map).replace({np.nan: None})
            overbought = overbought.rename(columns=rename_map).replace({np.nan: None})
            
            timestamp_str = datetime.now().isoformat()
            result_data = {
                "top_performers": top_performers.to_dict(orient="records"),
                "oversold": oversold.to_dict(orient="records"),
                "overbought": overbought.to_dict(orient="records"),
                "last_updated": timestamp_str
            }
            
            cached_screener_result["timestamp"] = timestamp_str
            cached_screener_result["data"] = result_data
            save_screener_cache(cached_screener_result)
            return result_data
        except Exception as e:
            logger.error(f"ç¯©é¸å™¨éŒ¯èª¤: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))

@router.post("/api/klines")
async def get_klines_data(request: KlineRequest):
    """ç²å– K ç·šæ•¸æ“šä¾›åœ–è¡¨é¡¯ç¤º"""
    try:
        loop = asyncio.get_running_loop()
        df = await loop.run_in_executor(
            None,
            lambda: get_klines(
                symbol=request.symbol,
                exchange=request.exchange,
                interval=request.interval,
                limit=request.limit
            )
        )

        if df is None or df.empty:
            raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ° {request.symbol} çš„æ•¸æ“š")

        klines = []
        for _, row in df.iterrows():
            klines.append({
                "time": int(row['timestamp'].timestamp()) if hasattr(row['timestamp'], 'timestamp') else int(row['timestamp'] / 1000),
                "open": float(row['open']),
                "high": float(row['high']),
                "low": float(row['low']),
                "close": float(row['close'])
            })

        return {
            "symbol": request.symbol,
            "interval": request.interval,
            "klines": klines
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç²å– K ç·šæ•¸æ“šå¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/api/funding-rates")
async def get_funding_rates(refresh: bool = False):
    """
    ç²å–æ‰€æœ‰å¹£ç¨®çš„è³‡é‡‘è²»ç‡ã€‚
    è³‡é‡‘è²»ç‡ç‚ºæ­£è¡¨ç¤ºå¤šé ­ä»˜çµ¦ç©ºé ­ï¼ˆå¸‚å ´çœ‹å¤šï¼‰ï¼Œè² å€¼è¡¨ç¤ºç©ºé ­ä»˜çµ¦å¤šé ­ï¼ˆå¸‚å ´çœ‹ç©ºï¼‰ã€‚
    """
    try:
        # å¦‚æœè¦æ±‚åˆ·æ–°æˆ–å¿«å–ç‚ºç©ºï¼Œå‰‡æ›´æ–°
        if refresh or not FUNDING_RATE_CACHE.get("data"):
            await update_funding_rates()

        data = FUNDING_RATE_CACHE.get("data", {})
        timestamp = FUNDING_RATE_CACHE.get("timestamp")

        # è¨ˆç®—æ¥µç«¯å€¼çµ±è¨ˆ
        rates = [(sym, info.get("fundingRate", 0)) for sym, info in data.items()]
        sorted_by_rate = sorted(rates, key=lambda x: x[1], reverse=True)

        # å‰5å€‹æœ€é«˜ï¼ˆå¤šé ­æ“æ“ ï¼‰
        top_bullish = sorted_by_rate[:5]
        # å¾Œ5å€‹æœ€ä½ï¼ˆç©ºé ­æ“æ“ ï¼‰
        top_bearish = sorted_by_rate[-5:][::-1]

        return {
            "timestamp": timestamp,
            "total_count": len(data),
            "data": data,
            "top_bullish": [{"symbol": s, "fundingRate": r} for s, r in top_bullish],
            "top_bearish": [{"symbol": s, "fundingRate": r} for s, r in top_bearish]
        }
    except Exception as e:
        logger.error(f"ç²å–è³‡é‡‘è²»ç‡å¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/api/funding-rate/{symbol}")
async def get_single_funding_rate(symbol: str):
    """ç²å–å–®å€‹å¹£ç¨®çš„è³‡é‡‘è²»ç‡"""
    try:
        base_symbol = symbol.upper().replace("USDT", "").replace("-SWAP", "").replace("-", "")

        # å…ˆæª¢æŸ¥å¿«å–
        if FUNDING_RATE_CACHE.get("data") and base_symbol in FUNDING_RATE_CACHE["data"]:
            return FUNDING_RATE_CACHE["data"][base_symbol]

        # å¿«å–ä¸­æ²’æœ‰ï¼Œç›´æ¥æŸ¥è©¢
        okx = OKXAPIConnector()
        instId = f"{base_symbol}-USDT-SWAP"
        result = okx.get_funding_rate(instId)

        if result.get("code") == "0" and result.get("data"):
            data = result["data"][0]
            return {
                "symbol": base_symbol,
                "instId": instId,
                "fundingRate": float(data.get("fundingRate", 0)) * 100,
                "nextFundingRate": float(data.get("nextFundingRate", 0)) * 100 if data.get("nextFundingRate") else None,
                "fundingTime": data.get("fundingTime"),
                "nextFundingTime": data.get("nextFundingTime")
            }
        return {"error": "Not found"}
    except Exception as e:
        logger.error(f"Error fetching single funding rate: {e}")
        return {"error": str(e)}

@router.get("/api/funding-rate-history/{symbol}")
async def get_funding_rate_history(symbol: str):
    """ç²å–è³‡é‡‘è²»ç‡æ­·å²æ•¸æ“š"""
    try:
        # Normalize symbol (e.g. BTC -> BTC-USDT-SWAP)
        base = symbol.upper().replace("-USDT", "").replace("-SWAP", "").replace("USDT", "")
        instId = f"{base}-USDT-SWAP"
        
        logger.info(f"[History] Fetching for symbol: {symbol} -> instId: {instId}")

        okx = OKXAPIConnector()
        
        # Get the running event loop
        loop = asyncio.get_running_loop()
        
        # Use run_in_executor to avoid blocking event loop
        result = await loop.run_in_executor(None, okx.get_funding_rate_history, instId)
        
        if result.get("code") == "0" and result.get("data"):
            history = []
            for item in result["data"]:
                history.append({
                    "time": item["fundingTime"],
                    "rate": float(item["fundingRate"]) * 100, # Convert to percentage
                    "realRate": float(item["realizedRate"]) * 100 if "realizedRate" in item else float(item["fundingRate"]) * 100
                })
            # OKX returns newest first, reverse to show chronological order
            return {"data": history[::-1], "symbol": base}
        
        return {"error": "Failed to fetch history", "details": result}
    except Exception as e:
        logger.error(f"Error fetching history: {e}")
        return {"error": str(e)}

@router.get("/api/market-pulse/{symbol}")
async def get_market_pulse_api(
    symbol: str,
    sources: Optional[str] = None,
    refresh: bool = False,
    deep_analysis: bool = False,
    x_user_llm_key: Optional[str] = Header(None),
    x_user_llm_provider: Optional[str] = Header(None)
):
    """
    ç²å–å¸‚å ´è„ˆå‹•åˆ†æ

    åˆ†å±¤è¨­è¨ˆï¼š
    - é è¨­æ¨¡å¼ï¼šè®€å–å…¬å…±å¿«å–ï¼ˆå¾Œå°å·²åˆ†æå¥½çš„æ•¸æ“šï¼‰
    - æ·±åº¦åˆ†ææ¨¡å¼ï¼šdeep_analysis=true + ç§äººé‡‘é‘° â†’ å³æ™‚ä½¿ç”¨ç”¨æˆ¶ API Key åˆ†æ
    """
    try:
        base_symbol = symbol.upper().replace("USDT", "").replace("BUSD", "").replace("-", "")

        # 1. å„ªå…ˆè®€å–å…¬å…±å¿«å–ï¼ˆé™¤éç”¨æˆ¶æ˜ç¢ºè¦æ±‚æ·±åº¦åˆ†æï¼‰
        if not deep_analysis and base_symbol in MARKET_PULSE_CACHE:
            cached_data = MARKET_PULSE_CACHE[base_symbol].copy()  # è¿”å›å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹å¿«å–
            cached_data["source_mode"] = "public_cache"  # æ¨™è¨˜æ•¸æ“šä¾†æº
            return cached_data

        # 2. æ·±åº¦åˆ†ææ¨¡å¼ï¼šç”¨æˆ¶é¸æ“‡ä½¿ç”¨ç§äººé‡‘é‘°å³æ™‚åˆ†æ
        if deep_analysis and x_user_llm_key and x_user_llm_provider:
            try:
                from utils.llm_client import create_llm_client_from_config
                from analysis.market_pulse import MarketPulseAnalyzer

                logger.info(f"ğŸ”¬ Deep Analysis Mode: Using User Key for {base_symbol}")
                user_client, _ = create_llm_client_from_config({
                    "provider": x_user_llm_provider,
                    "api_key": x_user_llm_key
                })

                analyzer = MarketPulseAnalyzer(client=user_client)
                loop = asyncio.get_running_loop()
                enabled_sources = sources.split(',') if sources else None

                result = await loop.run_in_executor(None, lambda: analyzer.analyze_movement(base_symbol, enabled_sources=enabled_sources))

                # æ·±åº¦åˆ†æçµæœä¹Ÿæ›´æ–°åˆ°å…¬å…±å¿«å–ï¼Œè®“å…¶ä»–äººä¹Ÿå—ç›Š
                if result and "error" not in result:
                    result["source_mode"] = "deep_analysis"  # æ¨™è¨˜ç‚ºæ·±åº¦åˆ†æ
                    result["analyzed_by"] = x_user_llm_provider  # è¨˜éŒ„åˆ†æä¾†æº
                    MARKET_PULSE_CACHE[base_symbol] = result
                    save_market_pulse_cache()
                return result
            except Exception as e:
                logger.error(f"Deep analysis failed: {e}")
                # æ·±åº¦åˆ†æå¤±æ•—æ™‚ï¼Œå›é€€åˆ°å¿«å–
                if base_symbol in MARKET_PULSE_CACHE:
                    return MARKET_PULSE_CACHE[base_symbol]

        # 3. å¿«å–æœªå‘½ä¸­ï¼šç«‹å³åŸ·è¡ŒæŒ‰éœ€åˆ†æ (On-Demand Analysis)
        logger.info(f"Cache miss for {base_symbol}, triggering immediate analysis...")
        
        try:
            from analysis.market_pulse import get_market_pulse
            
            # ä½¿ç”¨é è¨­ä¾†æº
            enabled_sources = sources.split(',') if sources else None
            loop = asyncio.get_running_loop()
            
            # ç«‹å³åŸ·è¡Œåˆ†æ
            result = await loop.run_in_executor(None, lambda: get_market_pulse(base_symbol, enabled_sources=enabled_sources))
            
            if result and "error" not in result:
                # æˆåŠŸå¾Œå¯«å…¥å¿«å–ï¼Œé€ ç¦å¾ŒçºŒè«‹æ±‚
                result["source_mode"] = "on_demand"
                MARKET_PULSE_CACHE[base_symbol] = result
                # ç•°æ­¥ä¿å­˜åˆ°æª”æ¡ˆï¼Œä¸é˜»å¡
                asyncio.create_task(asyncio.to_thread(save_market_pulse_cache))
                return result
            else:
                # åˆ†æå¤±æ•—çš„ fallback
                logger.warning(f"On-demand analysis failed for {base_symbol}: {result.get('error')}")
                # ç¹¼çºŒå‘ä¸‹åŸ·è¡Œï¼Œè¿”å› pending ç‹€æ…‹
                
        except Exception as e:
            logger.error(f"Error during on-demand analysis for {base_symbol}: {e}")

        return {
            "symbol": base_symbol,
            "status": "pending",
            "source_mode": "awaiting_update",
            "message": "åˆ†æä¸­ï¼Œè«‹ç¨å€™å†è©¦",
            "current_price": 0,
            "change_24h": 0,
            "change_1h": 0,
            "report": {
                "summary": "ç³»çµ±æ­£åœ¨ç‚ºæ­¤å¹£ç¨®ç”Ÿæˆåˆå§‹å ±å‘Šï¼Œè«‹ç¨å¾Œåˆ·æ–°é é¢ã€‚",
                "key_points": [],
                "highlights": [],
                "risks": []
            }
        }
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¸‚å ´è„ˆå‹•åˆ†æå¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/api/market-pulse/refresh-all")
async def api_refresh_all_market_pulse(request: RefreshPulseRequest):
    """Trigger a global refresh of specified Market Pulse targets immediately."""
    try:
        timestamp = await refresh_all_market_pulse_data(request.symbols)
        return {"status": "success", "timestamp": timestamp}
    except Exception as e:
        logger.error(f"Manual refresh failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/api/market-pulse/progress")
async def get_market_pulse_progress():
    """Get the current status of background analysis task."""
    return ANALYSIS_STATUS
