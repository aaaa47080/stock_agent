"""
Agent V3 å¢å¼·ç‰ˆ Human-in-the-Loop (HITL) Manager

ç”± LLM æ±ºå®šä½•æ™‚éœ€è¦è©¢å•ä½¿ç”¨è€…ï¼Œè€Œéå›ºå®šæ™‚æ©Ÿ
"""
from typing import Dict, Any, Optional, Tuple, List
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum

from langchain_core.messages import HumanMessage, SystemMessage

from .models import HITLTriggerType, ConversationContext


@dataclass
class HITLQuestion:
    """HITL å•é¡Œå®šç¾©"""
    question: str
    question_type: HITLTriggerType
    context: Dict[str, Any] = field(default_factory=dict)
    options: List[str] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class HITLResponse:
    """HITL å›æ‡‰è¨˜éŒ„"""
    question: HITLQuestion
    user_response: str
    responded_at: datetime = field(default_factory=datetime.now)


class EnhancedHITLManager:
    """
    å¢å¼·ç‰ˆ Human-in-the-Loop Manager

    èˆ‡åŸç‰ˆä¸åŒï¼š
    1. ç”± LLM æ±ºå®šæ˜¯å¦éœ€è¦è©¢å•ä½¿ç”¨è€…
    2. æ”¯æ´å¤šç¨®è©¢å•é¡å‹
    3. è¨˜éŒ„ä½¿ç”¨è€…å›é¥‹ç”¨æ–¼å­¸ç¿’
    4. å¯é…ç½®è©¢å•ç­–ç•¥
    """

    SHOULD_ASK_PROMPT = """ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©æ‰‹ï¼Œè² è²¬åˆ¤æ–·æ˜¯å¦éœ€è¦å‘ä½¿ç”¨è€…è©¢å•æ›´å¤šè³‡è¨Šã€‚

é‡è¦ï¼šé€™æ˜¯ä¸€å€‹åŠ å¯†è²¨å¹£åˆ†æç³»çµ±ï¼Œåªèƒ½è™•ç†ï¼š
- åŠ å¯†è²¨å¹£ç›¸é—œå•é¡Œï¼ˆåƒ¹æ ¼ã€æ–°èã€æŠ€è¡“åˆ†æï¼‰
- ä¸€èˆ¬å°è©±å’Œå•å€™

ç³»çµ±ç„¡æ³•è™•ç†ï¼š
- å¤©æ°£æŸ¥è©¢
- è¨‚ç¥¨è¨‚æˆ¿
- ç¶²è³¼æˆ–æ”¯ä»˜
- å…¶ä»–èˆ‡åŠ å¯†è²¨å¹£ç„¡é—œçš„åŠŸèƒ½

ç•¶å‰å°è©±ä¸Šä¸‹æ–‡ï¼š
{context}

ç•¶å‰ç‹€æ…‹ï¼š{state}

è«‹åˆ¤æ–·ï¼š
1. ä½¿ç”¨è€…çš„è«‹æ±‚æ˜¯å¦åœ¨ç³»çµ±èƒ½åŠ›ç¯„åœå…§ï¼Ÿ
2. å¦‚æœè¶…å‡ºèƒ½åŠ›ç¯„åœï¼Œshould_ask å¿…é ˆç‚º false
3. å¦‚æœåœ¨èƒ½åŠ›ç¯„åœå…§ä½†è³‡è¨Šä¸è¶³ï¼Œæ˜¯å¦éœ€è¦è©¢å•ï¼Ÿ

å•é¡Œé¡å‹èªªæ˜ï¼š
- info_needed: éœ€è¦æ›´å¤šè³‡è¨Šï¼ˆå¦‚ç¼ºå°‘å¹£ç¨®åç¨±ï¼‰
- preference: è©¢å•ä½¿ç”¨è€…åå¥½ï¼ˆå¦‚åˆ†ææ·±åº¦ï¼‰
- confirmation: ç¢ºèªé‡è¦æ±ºç­–
- satisfaction: è©¢å•æ»¿æ„åº¦
- clarification: æ¾„æ¸…æ¨¡ç³Šçš„å•é¡Œ

è«‹ä»¥ JSON æ ¼å¼å›è¦†ï¼š
{{
    "should_ask": true/false,
    "question": "å•é¡Œå…§å®¹ï¼ˆå¦‚æœ should_ask ç‚º trueï¼‰",
    "type": "å•é¡Œé¡å‹",
    "reason": "ç‚ºä»€éº¼éœ€è¦ï¼ˆæˆ–ä¸éœ€è¦ï¼‰è©¢å•",
    "out_of_scope": true/false
}}
"""

    ASK_QUESTION_PROMPT = """æ ¹æ“šä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆä¸€å€‹å‹å–„çš„å•é¡Œä¾†è©¢å•ä½¿ç”¨è€…ã€‚

ä¸Šä¸‹æ–‡ï¼š{context}
å•é¡Œé¡å‹ï¼š{question_type}
ç›®çš„ï¼š{purpose}

è«‹ç”Ÿæˆä¸€å€‹ï¼š
1. ç°¡æ½”æ˜ç­çš„å•é¡Œ
2. èªæ°£å‹å–„
3. ä½¿ç”¨ç¹é«”ä¸­æ–‡

åªå›è¦†å•é¡Œæœ¬èº«ï¼Œä¸è¦å…¶ä»–å…§å®¹ã€‚"""

    def __init__(
        self,
        llm_client,
        auto_ask_threshold: float = 0.7,
        max_questions_per_session: int = 5
    ):
        """
        åˆå§‹åŒ– HITL Manager

        Args:
            llm_client: LangChain LLM å®¢æˆ¶ç«¯
            auto_ask_threshold: è‡ªå‹•è©¢å•çš„ä¿¡å¿ƒåº¦é–¾å€¼
            max_questions_per_session: æ¯å€‹æœƒè©±æœ€å¤šè©¢å•æ¬¡æ•¸
        """
        self.llm = llm_client
        self.auto_ask_threshold = auto_ask_threshold
        self.max_questions = max_questions_per_session

        # ç•¶å‰å¾…è™•ç†çš„å•é¡Œ
        self._pending_question: Optional[HITLQuestion] = None
        # å•ç­”æ­·å²
        self._qa_history: List[HITLResponse] = []
        # æœƒè©±çµ±è¨ˆ
        self._session_stats = {
            "total_questions": 0,
            "total_responses": 0,
            "by_type": {}
        }

    def should_ask_user(
        self,
        context: ConversationContext,
        current_state: str = "processing"
    ) -> Tuple[bool, str, HITLTriggerType]:
        """
        ä½¿ç”¨ LLM åˆ¤æ–·æ˜¯å¦éœ€è¦è©¢å•ä½¿ç”¨è€…

        Args:
            context: å°è©±ä¸Šä¸‹æ–‡
            current_state: ç•¶å‰è™•ç†ç‹€æ…‹

        Returns:
            (should_ask: bool, question: str, question_type: HITLTriggerType)
        """
        # æª¢æŸ¥æ˜¯å¦è¶…éæœ€å¤§è©¢å•æ¬¡æ•¸
        if self._session_stats["total_questions"] >= self.max_questions:
            return (False, "", HITLTriggerType.INFO_NEEDED)

        prompt = self.SHOULD_ASK_PROMPT.format(
            context=context.to_prompt_string(),
            state=current_state
        )

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            result = self._parse_response(response.content)

            should_ask = result.get("should_ask", False)
            question = result.get("question", "")
            q_type = self._parse_question_type(result.get("type", "info_needed"))

            return (should_ask, question, q_type)

        except Exception as e:
            print(f"[HITL] åˆ¤æ–·éŒ¯èª¤: {e}")
            return (False, "", HITLTriggerType.INFO_NEEDED)

    def ask(
        self,
        question: str,
        question_type: HITLTriggerType = HITLTriggerType.INFO_NEEDED,
        options: List[str] = None
    ) -> str:
        """
        å‘ä½¿ç”¨è€…æå•ä¸¦ç­‰å¾…å›æ‡‰

        åœ¨ CLI ç’°å¢ƒä¸­ç›´æ¥åˆ—å°ä¸¦ç­‰å¾…è¼¸å…¥
        åœ¨éäº¤äº’å¼ç’°å¢ƒä¸­è¿”å›ç©ºå­—ä¸²

        Args:
            question: å•é¡Œå…§å®¹
            question_type: å•é¡Œé¡å‹
            options: é¸é …åˆ—è¡¨ï¼ˆå¯é¸ï¼‰

        Returns:
            ä½¿ç”¨è€…çš„å›æ‡‰ï¼ˆéäº¤äº’å¼ç’°å¢ƒè¿”å›ç©ºå­—ä¸²ï¼‰
        """
        # æª¢æŸ¥æ˜¯å¦åœ¨äº¤äº’å¼ç’°å¢ƒä¸­
        import sys
        if not sys.stdin.isatty():
            # éäº¤äº’å¼ç’°å¢ƒï¼Œè·³éè©¢å•
            return ""

        # å‰µå»ºå•é¡Œè¨˜éŒ„
        q = HITLQuestion(
            question=question,
            question_type=question_type,
            options=options or []
        )
        self._pending_question = q

        # é¡¯ç¤ºå•é¡Œ
        print(f"\nğŸ¤” {question}")
        if options:
            for i, opt in enumerate(options, 1):
                print(f"   {i}. {opt}")
        print()

        try:
            # ç­‰å¾…ä½¿ç”¨è€…è¼¸å…¥ï¼ˆè¨­ç½®è¶…æ™‚ï¼‰
            response = input("ä½ çš„å›ç­” > ").strip()

            # è™•ç†é¸é …è¼¸å…¥
            if options and response.isdigit():
                idx = int(response) - 1
                if 0 <= idx < len(options):
                    response = options[idx]

            # è¨˜éŒ„å›æ‡‰
            self._record_response(q, response)

            return response

        except (EOFError, KeyboardInterrupt):
            # ç„¡æ³•è®€å–è¼¸å…¥ï¼Œè¿”å›ç©ºå­—ä¸²
            return ""

    def ask_if_needed(
        self,
        context: ConversationContext,
        current_state: str = "processing"
    ) -> Tuple[bool, str]:
        """
        å¦‚æœéœ€è¦å‰‡è©¢å•ä½¿ç”¨è€…

        çµåˆ should_ask_user å’Œ ask çš„ä¾¿æ·æ–¹æ³•

        Args:
            context: å°è©±ä¸Šä¸‹æ–‡
            current_state: ç•¶å‰ç‹€æ…‹

        Returns:
            (asked: bool, response: str)
        """
        should_ask, question, q_type = self.should_ask_user(context, current_state)

        if should_ask and question:
            response = self.ask(question, q_type)
            return (True, response)

        return (False, "")

    def generate_question(
        self,
        purpose: str,
        question_type: HITLTriggerType,
        context: str = ""
    ) -> str:
        """
        è®“ LLM ç”Ÿæˆå•é¡Œ

        Args:
            purpose: å•é¡Œç›®çš„
            question_type: å•é¡Œé¡å‹
            context: ä¸Šä¸‹æ–‡è³‡è¨Š

        Returns:
            ç”Ÿæˆçš„å•é¡Œ
        """
        prompt = self.ASK_QUESTION_PROMPT.format(
            context=context,
            question_type=question_type.value,
            purpose=purpose
        )

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return response.content.strip()
        except Exception as e:
            print(f"[HITL] ç”Ÿæˆå•é¡ŒéŒ¯èª¤: {e}")
            return f"è«‹æä¾›æ›´å¤šé—œæ–¼ã€Œ{purpose}ã€çš„è³‡è¨Š"

    def get_pending_question(self) -> Optional[HITLQuestion]:
        """ç²å–ç•¶å‰å¾…è™•ç†çš„å•é¡Œ"""
        return self._pending_question

    def has_pending_question(self) -> bool:
        """æ˜¯å¦æœ‰å¾…è™•ç†çš„å•é¡Œ"""
        return self._pending_question is not None

    def clear_pending(self) -> None:
        """æ¸…é™¤å¾…è™•ç†å•é¡Œ"""
        self._pending_question = None

    def get_history(self, limit: int = 20) -> List[dict]:
        """
        ç²å–å•ç­”æ­·å²

        Args:
            limit: è¿”å›è¨˜éŒ„æ•¸é‡é™åˆ¶

        Returns:
            å•ç­”è¨˜éŒ„åˆ—è¡¨
        """
        recent = self._qa_history[-limit:]
        return [
            {
                "question": r.question.question,
                "type": r.question.question_type.value,
                "response": r.user_response,
                "time": r.responded_at.isoformat()
            }
            for r in recent
        ]

    def get_stats(self) -> dict:
        """ç²å–çµ±è¨ˆè³‡è¨Š"""
        return self._session_stats.copy()

    def reset(self) -> None:
        """é‡ç½®æœƒè©±"""
        self._pending_question = None
        self._qa_history.clear()
        self._session_stats = {
            "total_questions": 0,
            "total_responses": 0,
            "by_type": {}
        }

    def _record_response(self, question: HITLQuestion, response: str) -> None:
        """è¨˜éŒ„å•ç­”"""
        record = HITLResponse(question=question, user_response=response)
        self._qa_history.append(record)

        # æ›´æ–°çµ±è¨ˆ
        self._session_stats["total_questions"] += 1
        self._session_stats["total_responses"] += 1

        type_key = question.question_type.value
        self._session_stats["by_type"][type_key] = \
            self._session_stats["by_type"].get(type_key, 0) + 1

        self._pending_question = None

    def _parse_response(self, content: str) -> dict:
        """è§£æ LLM å›æ‡‰ç‚º JSON"""
        import json
        import re

        # å˜—è©¦æå– JSON
        json_match = re.search(r'\{[^{}]*\}', content, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group())
            except:
                pass

        # è§£æå¤±æ•—ï¼Œè¿”å›é»˜èªå€¼
        return {
            "should_ask": False,
            "question": "",
            "type": "info_needed",
            "reason": "ç„¡æ³•è§£æ LLM å›æ‡‰"
        }

    def _parse_question_type(self, type_str: str) -> HITLTriggerType:
        """è§£æå•é¡Œé¡å‹"""
        type_map = {
            "info_needed": HITLTriggerType.INFO_NEEDED,
            "preference": HITLTriggerType.PREFERENCE,
            "confirmation": HITLTriggerType.CONFIRMATION,
            "satisfaction": HITLTriggerType.SATISFACTION,
            "clarification": HITLTriggerType.CLARIFICATION,
        }

        type_lower = type_str.lower().strip()
        return type_map.get(type_lower, HITLTriggerType.INFO_NEEDED)
