"""
DuckDuckGo å³æ™‚æœå°‹å·¥å…·

ä½¿ç”¨ ddgs å¥—ä»¶ï¼Œæ”¯æ´åœ°ç†é™åˆ¶ï¼Œä¸¦ä½¿ç”¨ Playwright æå–å®Œæ•´å…§å®¹
"""

from langchain_core.tools import tool
from ddgs import DDGS
from playwright.sync_api import sync_playwright
import time
import re


def get_page_content(url: str) -> str:
    """
    ä½¿ç”¨ Playwright å¾ç¶²é ç²å–å®Œæ•´å…§å®¹
    """
    try:
        # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆç¶²å€
        if not url.startswith(('http://', 'https://')):
            return "[ç„¡æ•ˆç¶²å€]"
        
        # æª¢æŸ¥æ˜¯å¦ç‚º YouTube æˆ–å…¶ä»–ç‰¹æ®Šç¶²ç«™
        if 'youtube.com' in url or 'youtu.be' in url:
            return "[å½±ç‰‡å…§å®¹ï¼Œç„¡æ³•æå–æ–‡å­—]"
        
        with sync_playwright() as p:
            # å•Ÿå‹•ç€è¦½å™¨
            browser = p.chromium.launch(headless=True, timeout=30000)
            page = browser.new_page()
            
            # è¨­ç½®ç”¨æˆ¶ä»£ç†ä»¥é¿å…è¢«å°é–
            page.set_extra_http_headers({
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            })
            
            # è¨ªå•é é¢
            page.goto(url, timeout=30000, wait_until="domcontentloaded")
            
            # ç­‰å¾…é é¢åŠ è¼‰å®Œæˆ
            time.sleep(2)
            
            # å˜—è©¦ç²å–é é¢ä¸»è¦å…§å®¹
            try:
                # å„ªå…ˆç²å–æ–‡ç« å…§å®¹
                content_selectors = [
                    'article',
                    '.content', 
                    '.post', 
                    '.entry-content',
                    'main',
                    '.main-content',
                    '#content',
                    '.article-content',
                    '.post-content'
                ]
                
                content = None
                for selector in content_selectors:
                    try:
                        content = page.query_selector(selector)
                        if content:
                            break
                    except:
                        continue
                
                if content:
                    text = content.inner_text()
                else:
                    # å¦‚æœç‰¹å®šé¸æ“‡å™¨æ‰¾ä¸åˆ°ï¼Œç²å– body å…§å®¹
                    text = page.inner_text('body')
                
                # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¤šé¤˜çš„ç©ºç™½å­—ç¬¦
                text = re.sub(r'\s+', ' ', text).strip()
                
            except Exception as e:
                print(f"  âŒ é¸æ“‡å™¨ç²å–å¤±æ•—: {str(e)}")
                # å¦‚æœé¸æ“‡å™¨å¤±æ•—ï¼Œç›´æ¥ç²å– body æ–‡æœ¬
                try:
                    text = page.inner_text('body')
                    text = re.sub(r'\s+', ' ', text).strip()
                except:
                    text = "[å…§å®¹ç²å–å¤±æ•—]"
            
            browser.close()
            
            # é™åˆ¶å…§å®¹é•·åº¦ä¸¦æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆå…§å®¹
            if text and len(text.strip()) > 10:  # ç¢ºä¿æœ‰å¯¦éš›å…§å®¹
                # if len(text) > 2000:
                #     text = text[:2000] + "\n... (å…§å®¹éé•·ï¼Œå·²æˆªæ–·)"
                return text
            else:
                return "[å…§å®¹éçŸ­æˆ–ç„¡æ³•æå–æœ‰æ•ˆå…§å®¹]"
            
    except Exception as e:
        print(f"  âŒ ç²å–é é¢å…§å®¹å¤±æ•— {url}: {str(e)}")
        return f"[å…§å®¹ç²å–å¤±æ•—: {str(e)}]"


@tool
def search_duckduckgo_realtime(query: str, max_results: int = 5, region: str = "tw-tzh", safe_search: str = "moderate", get_full_content: bool = True) -> str:
    """
    å³æ™‚æœå°‹ DuckDuckGoï¼Œç²å–æœ€æ–°çš„ç¶²è·¯è³‡è¨Šã€‚

    é€™å€‹å·¥å…·é©åˆç”¨æ–¼æŸ¥è©¢ï¼š
    - æœ€æ–°è³‡è¨Šå’Œè¶¨å‹¢
    - ä¸€èˆ¬ç¶²è·¯æœå°‹çµæœ
    - éš±ç§ä¿è­·æœå°‹ï¼ˆDuckDuckGo ä¸è¿½è¹¤ç”¨æˆ¶ï¼‰
    - æ›¿ä»£ Google æœå°‹çš„é¸æ“‡

    Args:
        query: æœå°‹é—œéµå­—ï¼ˆå¦‚ï¼š"æœ€æ–°ç–«æƒ…æ–°è"ã€"Pythonæ•™å­¸"ï¼‰
        max_results: è¿”å›çµæœæ•¸é‡ï¼Œé è¨­ 5 ç­†ï¼ˆç¯„åœ 1-10ï¼‰
        region: åœ°ç†å€åŸŸä»£ç¢¼ï¼Œé è¨­ "tw-tzh"ï¼ˆå°ç£ç¹é«”ä¸­æ–‡ï¼‰
                å¸¸ç”¨ä»£ç¢¼ï¼š
                - "tw-tzh": å°ç£ç¹é«”ä¸­æ–‡
                - "hk-tzh": é¦™æ¸¯ç¹é«”ä¸­æ–‡  
                - "cn-zh": ä¸­åœ‹ç°¡é«”ä¸­æ–‡
                - "wt-wt": å…¨çƒï¼ˆé è¨­ï¼‰
                - "us-en": ç¾åœ‹è‹±èª
        safe_search: å®‰å…¨æœå°‹ç­‰ç´šï¼Œé è¨­ "moderate"
                - "strict": åš´æ ¼
                - "moderate": ä¸­ç­‰
                - "off": é—œé–‰
        get_full_content: æ˜¯å¦ç²å–å®Œæ•´é é¢å…§å®¹ï¼Œé è¨­ True

    Returns:
        æ ¼å¼åŒ–çš„æœå°‹çµæœï¼ŒåŒ…å«æ¨™é¡Œã€URL å’Œæè¿°/å®Œæ•´å…§å®¹
    """
    try:
        # é™åˆ¶æœå°‹çµæœæ•¸é‡
        max_results = max(1, min(max_results, 10))

        print(f"[DuckDuckGo å³æ™‚æœå°‹] é—œéµå­—: {query}, çµæœæ•¸: {max_results}, å€åŸŸ: {region}, å®‰å…¨æœå°‹: {safe_search}")
        print(f"[DuckDuckGo å³æ™‚æœå°‹] ğŸ“ å®Œæ•´æŸ¥è©¢å­—ä¸²: ã€Œ{query}ã€ï¼ˆé•·åº¦: {len(query)} å­—å…ƒï¼‰")

        print(f"[DuckDuckGo å³æ™‚æœå°‹] ğŸ” é–‹å§‹æœå°‹...")
        
        # ä½¿ç”¨ duckduckgo_search å¥—ä»¶
        with DDGS() as ddgs:
            # åŸ·è¡Œæœå°‹ï¼ŒæŒ‡å®šå€åŸŸ
            results = list(ddgs.text(
                query, 
                max_results=max_results, 
                region=region, 
                safesearch=safe_search
            ))
        
        if not results:
            return f"âŒ DuckDuckGo å³æ™‚æœå°‹ï¼šæœªæ‰¾åˆ°é—œæ–¼ã€Œ{query}ã€çš„ç›¸é—œè³‡è¨Šã€‚"

        print(f"[DuckDuckGo å³æ™‚æœå°‹] æ‰¾åˆ° {len(results)} å€‹çµæœ")
        
        # æ ¼å¼åŒ–æœå°‹çµæœ
        formatted_results = []
        formatted_results.append(f"ä»¥ä¸‹æ˜¯å¾ DuckDuckGo å³æ™‚æœå°‹åˆ°çš„ç›¸é—œè³‡è¨Šï¼ˆé—œéµå­—ï¼šã€Œ{query}ã€ï¼Œå€åŸŸï¼š{region}ï¼‰ï¼š\n")
        formatted_results.append("**æœå°‹çµæœ**")

        for i, result in enumerate(results, 1):
            title = result.get('title', 'N/A')
            url = result.get('href', result.get('url', 'N/A'))
            snippet = result.get('body', result.get('snippet', 'N/A'))

            # ğŸ”§ éæ¿¾æ˜é¡¯ç„¡é—œçš„çµæœ
            if url == 'N/A' or not url or url == '':
                print(f"  âš ï¸ çµæœ {i} æ²’æœ‰æœ‰æ•ˆ URLï¼Œè·³é")
                continue

            # æª¢æŸ¥æ˜¯å¦ç‚ºæ˜é¡¯çš„åƒåœ¾çµæœï¼ˆQuizletå­¸ç¿’å¡ç‰‡ã€é©—è­‰é é¢ç­‰ï¼‰
            low_quality_indicators = ['flashcards', 'flash-cards', 'confirm you are a human', 'not a bot', 'Reference ID']
            title_and_snippet = f"{title} {snippet}".lower()
            if any(indicator.lower() in title_and_snippet for indicator in low_quality_indicators):
                print(f"  âš ï¸ çµæœ {i} ç–‘ä¼¼ä½è³ªé‡å…§å®¹ï¼ˆ{title[:50]}...ï¼‰ï¼Œè·³é")
                continue

            # ä½¿ç”¨ã€Šã€‹æ ¼å¼ï¼Œèˆ‡å…¶ä»–å·¥å…·ä¿æŒä¸€è‡´
            formatted_results.append(f"\n{i}. ã€Š{url}ã€‹")
            formatted_results.append(f"   æ¨™é¡Œï¼š{title}")

            # ç²å–å®Œæ•´å…§å®¹æˆ–ä½¿ç”¨æ‘˜è¦
            if get_full_content and url and url.startswith(('http://', 'https://')):
                print(f"  â†’ æ­£åœ¨æå–çµæœ {i} çš„å®Œæ•´å…§å®¹...")
                print(f"     [Fetching: {url}]")
                
                # ç²å–å®Œæ•´å…§å®¹
                full_content = get_page_content(url)
                
                if full_content and not full_content.startswith(("[å…§å®¹ç²å–å¤±æ•—", "[ç„¡æ•ˆç¶²å€]", "[å½±ç‰‡å…§å®¹", "[å…§å®¹éçŸ­")):
                    print(f"  âœ… æˆåŠŸæå–å®Œæ•´å…§å®¹ï¼")
                    print(f"     å…§å®¹é•·åº¦: {len(full_content)} å­—å…ƒ")
                    formatted_results.append(f"   å…§å®¹ï¼š{full_content}")
                else:
                    print(f"  âš ï¸ å…§å®¹æå–å¤±æ•—æˆ–ç‚ºç‰¹æ®Šå…§å®¹ï¼Œä½¿ç”¨æ‘˜è¦ä»£æ›¿")
                    if snippet and snippet != 'N/A':
                        formatted_results.append(f"   æ‘˜è¦ï¼š{snippet}")
                    else:
                        formatted_results.append(f"   ï¼ˆç„¡æ³•æå–å®Œæ•´å…§å®¹ï¼š{full_content}ï¼‰")
            else:
                # ä¸ç²å–å®Œæ•´å…§å®¹ï¼Œåªä½¿ç”¨æ‘˜è¦
                if snippet and snippet != 'N/A':
                    formatted_results.append(f"   æ‘˜è¦ï¼š{snippet}")
                else:
                    formatted_results.append(f"   ï¼ˆç„¡æ‘˜è¦ï¼‰")

            formatted_results.append(f"   ä¾†æºï¼šDuckDuckGo å³æ™‚æœå°‹ï¼ˆå€åŸŸï¼š{region}ï¼‰\n")

        return "\n".join(formatted_results)

    except Exception as e:
        error_msg = f"âŒ DuckDuckGo å³æ™‚æœå°‹ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return error_msg


# ==================== å·¥å…·è¨»å†Š ====================

def register_duckduckgo_tool():
    """è¨»å†Š DuckDuckGo å³æ™‚æœå°‹å·¥å…·åˆ°å·¥å…·è¨»å†Šè¡¨"""
    from tools_config import register_tool, ToolConfig

    duckduckgo_tool_config = ToolConfig(
        id="duckduckgo_realtime_search",
        name="DuckDuckGo å³æ™‚æœå°‹",
        description="å³æ™‚æœå°‹ DuckDuckGoï¼Œç²å–æœ€æ–°ç¶²è·¯è³‡è¨Šã€æ–°èã€æŠ€è¡“å•é¡Œè§£ç­”ï¼ˆæ”¯æ´åœ°ç†é™åˆ¶ï¼Œä¿è­·éš±ç§ï¼‰",
        tool_func=search_duckduckgo_realtime,
        enabled=True,  # é è¨­å•Ÿç”¨
        support_medical=False,
        support_general=True,
        timeout=60,  # å¢åŠ è¶…æ™‚æ™‚é–“ï¼Œå› ç‚ºéœ€è¦æå–å®Œæ•´å…§å®¹
        retry_on_failure=False,
        metadata={
            "category": "external_search",
            "data_source": "duckduckgo",
            "search_type": "realtime",
            "privacy_focused": True,
            "supports_region_filter": True,
            "extracts_full_content": True
        }
    )

    register_tool(duckduckgo_tool_config)
    print("âœ… DuckDuckGo å³æ™‚æœå°‹å·¥å…·å·²è¨»å†Š")


# ==================== æ¸¬è©¦ç¨‹å¼ ====================

if __name__ == "__main__":
    # æ¸¬è©¦å·¥å…·
    print("ğŸ§ª æ¸¬è©¦ DuckDuckGo å³æ™‚æœå°‹å·¥å…·\n")

    # æ¸¬è©¦ 1ï¼šæœå°‹å°ç£ç–«æƒ…æ–°è
    print("æ¸¬è©¦ 1ï¼šæœå°‹ã€Œé é˜²ç™Œç—‡ã€ï¼ˆå€åŸŸï¼šå°ç£ï¼‰")
    print("=" * 80)
    
    result = search_duckduckgo_realtime.invoke({
        "query": "é é˜²ç™Œç—‡",
        "max_results": 2,
        "region": "tw-tzh",
        "safe_search": "moderate",
        "get_full_content": True
    })
    print(result)
    print("\n")