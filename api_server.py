import os
import sys
import json
import asyncio
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Optional, List, Dict, Any
from fastapi import FastAPI, Request, HTTPException, status
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

import uvicorn
from dotenv import load_dotenv

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("API")

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥ Python è·¯å¾‘
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

# å˜—è©¦å°å…¥ï¼Œè‹¥å¤±æ•—å‰‡è¨˜éŒ„éŒ¯èª¤
try:
    from interfaces.chat_interface import CryptoAnalysisBot
    from analysis.crypto_screener import screen_top_cryptos
    from core.config import (
        SUPPORTED_EXCHANGES, DEFAULT_INTERVAL, DEFAULT_KLINES_LIMIT,
        SCREENER_TARGET_SYMBOLS, SCREENER_UPDATE_INTERVAL_MINUTES
    )
    from core.database import add_to_watchlist, remove_from_watchlist, get_watchlist
    from data.market_data import get_klines
except ImportError as e:
    logger.critical(f"ç„¡æ³•å°å…¥æ ¸å¿ƒæ¨¡çµ„: {e}")
    sys.exit(1)

load_dotenv()

from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup: å˜—è©¦è¼‰å…¥å¿«å–
    load_screener_cache()
    load_market_pulse_cache()
    
    # Startup: å•Ÿå‹•èƒŒæ™¯ç¯©é¸å™¨æ›´æ–°ä»»å‹™
    asyncio.create_task(update_screener_task())
    # Startup: å•Ÿå‹• Market Pulse å®šæœŸæ›´æ–°ä»»å‹™
    asyncio.create_task(update_market_pulse_task())
    yield
    # Shutdown logic can go here if needed

app = FastAPI(title="Crypto Trading System API", version="1.1.0", lifespan=lifespan)

# --- å…¨åŸŸå¿«å– (Screener) ---
# ç”¨æ–¼å„²å­˜å¸‚å ´æƒæçµæœï¼Œé¿å…æ¯æ¬¡è«‹æ±‚éƒ½é‡æ–°é‹ç®—
cached_screener_result = {
    "timestamp": None,
    "data": None
}
SCREENER_CACHE_FILE = "analysis_results/screener_cache.json"

# --- å…¨åŸŸå¿«å– (Market Pulse) ---
# ç”¨æ–¼å„²å­˜å¸‚å ´è„ˆå‹• AI åˆ†æçµæœ
MARKET_PULSE_CACHE = {}
MARKET_PULSE_CACHE_FILE = "analysis_results/market_pulse_cache.json"
# å›ºå®šç›£æ§çš„å¹£ç¨®åˆ—è¡¨
MARKET_PULSE_TARGETS = ["BTC", "ETH", "SOL", "PI"]
# æ›´æ–°é »ç‡ (ç§’)
MARKET_PULSE_UPDATE_INTERVAL = 3600  # 1å°æ™‚

# Locks for concurrency control
screener_lock = asyncio.Lock()
symbol_locks = {} # {symbol: asyncio.Lock()}

def get_symbol_lock(symbol: str) -> asyncio.Lock:
    if symbol not in symbol_locks:
        symbol_locks[symbol] = asyncio.Lock()
    return symbol_locks[symbol]

def save_market_pulse_cache():
    """Save Market Pulse data to a JSON file."""
    try:
        os.makedirs(os.path.dirname(MARKET_PULSE_CACHE_FILE), exist_ok=True)
        with open(MARKET_PULSE_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(MARKET_PULSE_CACHE, f, ensure_ascii=False, indent=2)
        logger.info(f"Market Pulse cache saved to {MARKET_PULSE_CACHE_FILE}")
    except Exception as e:
        logger.error(f"Failed to save Market Pulse cache: {e}")

def load_market_pulse_cache():
    """Load Market Pulse data from the JSON file."""
    global MARKET_PULSE_CACHE
    try:
        if os.path.exists(MARKET_PULSE_CACHE_FILE):
            with open(MARKET_PULSE_CACHE_FILE, 'r', encoding='utf-8') as f:
                MARKET_PULSE_CACHE = json.load(f)
            logger.info(f"Loaded Market Pulse cache from {MARKET_PULSE_CACHE_FILE} ({len(MARKET_PULSE_CACHE)} symbols)")
    except Exception as e:
        logger.error(f"Failed to load Market Pulse cache: {e}")

async def update_single_market_pulse(symbol: str, fixed_sources: List[str]):
    """Helper to update a single symbol for Market Pulse."""
    from analysis.market_pulse import get_market_pulse
    loop = asyncio.get_running_loop()
    try:
        logger.info(f"[Background] Updating Market Pulse for {symbol}...")
        result = await loop.run_in_executor(
            None, 
            lambda: get_market_pulse(symbol, enabled_sources=fixed_sources)
        )
        
        if result and "error" not in result:
            MARKET_PULSE_CACHE[symbol] = result
            logger.info(f"[Background] Successfully updated {symbol}")
        else:
            logger.warning(f"[Background] Failed to update {symbol}: {result.get('error', 'Unknown error')}")
    except Exception as e:
        logger.error(f"[Background] Error updating {symbol}: {e}")

async def update_market_pulse_task():
    """Background task to update Market Pulse analysis periodically."""
    
    # å›ºå®šçš„æ–°èä¾†æºï¼Œç¢ºä¿å“è³ªä¸€è‡´
    FIXED_SOURCES = ['google', 'cryptopanic', 'newsapi', 'cryptocompare']
    
    # 1. Initial Fast Update (Concurrent)
    logger.info("ğŸš€ Starting initial Market Pulse analysis (Concurrent)...")
    tasks = [update_single_market_pulse(sym, FIXED_SOURCES) for sym in MARKET_PULSE_TARGETS]
    await asyncio.gather(*tasks)
    save_market_pulse_cache()
    logger.info("âœ… Initial Market Pulse analysis complete.")

    # 2. Periodic Update Loop
    while True:
        await asyncio.sleep(MARKET_PULSE_UPDATE_INTERVAL)
        try:
            logger.info("Starting scheduled Market Pulse update cycle...")
            
            # For periodic updates, we can do them sequentially or semi-concurrently to be gentle on APIs
            for symbol in MARKET_PULSE_TARGETS:
                await update_single_market_pulse(symbol, FIXED_SOURCES)
                await asyncio.sleep(5) # Gentle spacing
            
            save_market_pulse_cache()
            logger.info("Scheduled Market Pulse update complete.")
            
        except Exception as e:
            logger.error(f"Market Pulse task error: {e}")

def save_screener_cache(data: Dict[str, Any]):
    """Save screener data to a JSON file."""
    try:
        os.makedirs(os.path.dirname(SCREENER_CACHE_FILE), exist_ok=True)
        with open(SCREENER_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"Screener cache saved to {SCREENER_CACHE_FILE}")
    except Exception as e:
        logger.error(f"Failed to save screener cache: {e}")

def load_screener_cache():
    """Load screener data from the JSON file."""
    try:
        if os.path.exists(SCREENER_CACHE_FILE):
            with open(SCREENER_CACHE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            cached_screener_result["timestamp"] = data.get("timestamp")
            cached_screener_result["data"] = data.get("data")
            logger.info(f"Loaded screener cache from {SCREENER_CACHE_FILE} (Timestamp: {data.get('timestamp')})")
    except Exception as e:
        logger.error(f"Failed to load screener cache: {e}")

# --- å®‰å…¨æ€§å¼·åŒ–: CORS ---
# å…è¨±è·¨åŸŸè«‹æ±‚ï¼Œæ–¹ä¾¿å‰ç«¯é–‹ç™¼èˆ‡éƒ¨ç½²
origins = [
    "http://localhost",
    "http://localhost:3000",
    "http://localhost:8080",
    "https://app.minepi.com", # Pi Browser ç’°å¢ƒ
    "*", # é–‹ç™¼éšæ®µå…è¨±æ‰€æœ‰ï¼Œç”Ÿç”¢ç’°å¢ƒè«‹é™åˆ¶
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ– Bot
try:
    bot = CryptoAnalysisBot()
    logger.info("CryptoAnalysisBot åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"CryptoAnalysisBot åˆå§‹åŒ–å¤±æ•—: {e}")
    bot = None

# å®šç¾©è«‹æ±‚æ¨¡å‹
class QueryRequest(BaseModel):
    message: str
    interval: str = DEFAULT_INTERVAL
    limit: int = DEFAULT_KLINES_LIMIT
    manual_selection: Optional[List[str]] = None

class ScreenerRequest(BaseModel):
    exchange: str = SUPPORTED_EXCHANGES[0]
    symbols: Optional[List[str]] = None

class WatchlistRequest(BaseModel):
    user_id: str
    symbol: str

class KlineRequest(BaseModel):
    symbol: str
    exchange: str = SUPPORTED_EXCHANGES[0]
    interval: str = "1d"
    limit: int = 100

class BacktestRequest(BaseModel):
    symbol: str
    signal_type: str = "RSI" # RSI, MACD, MA_CROSS
    interval: str = "1h"


# --- èƒŒæ™¯ä»»å‹™ ---

async def update_screener_prices_fast():
    """
    å¿«é€Ÿæ›´æ–°ä»»å‹™ï¼šåªæ›´æ–° cached_screener_result ä¸­çš„åƒ¹æ ¼è³‡è¨Šã€‚
    ä¸é‡æ–°è¨ˆç®—æŒ‡æ¨™æˆ–æ’åï¼Œåƒ…æŠ“å–ç•¶å‰æœ€æ–°åƒ¹æ ¼ (Ticker)ã€‚
    """
    if cached_screener_result["data"] is None:
        return

    try:
        from data.data_fetcher import get_data_fetcher
        # ä½¿ç”¨ Binance å› ç‚º API éŸ¿æ‡‰å¿« (æˆ–æ ¹æ“šé…ç½®)
        fetcher = get_data_fetcher("binance") 
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦æ›´æ–°çš„ Symbol
        symbols = set()
        data = cached_screener_result["data"]
        
        for list_name in ["top_performers", "oversold", "overbought"]:
            if data.get(list_name):
                for item in data[list_name]:
                    symbols.add(item["Symbol"])
        
        if not symbols:
            return

        loop = asyncio.get_running_loop()
        all_tickers = await loop.run_in_executor(None, lambda: fetcher._make_request(fetcher.spot_base_url, "/ticker/24hr"))
        
        if not all_tickers:
            return

        # å»ºç«‹åƒ¹æ ¼æŸ¥æ‰¾è¡¨ {symbol: {price, change_percent}}
        price_map = {}
        for t in all_tickers:
            price_map[t['symbol']] = {
                'price': float(t['lastPrice']),
                'change': float(t['priceChangePercent'])
            }

        # æ›´æ–°å¿«å–ä¸­çš„æ•¸æ“š
        updated = False
        for list_name in ["top_performers", "oversold", "overbought"]:
            if data.get(list_name):
                for item in data[list_name]:
                    s = item["Symbol"].replace("/", "").replace("-", "")
                    if s in price_map:
                        item["Close"] = price_map[s]['price']
                        item["price_change_24h"] = price_map[s]['change']
                        updated = True
        
        if updated:
            if data.get("top_performers"):
                data["top_performers"].sort(key=lambda x: float(x.get("price_change_24h", 0)), reverse=True)

            timestamp_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            cached_screener_result["data"]["last_updated"] = timestamp_str
            cached_screener_result["timestamp"] = timestamp_str
            
    except Exception as e:
        pass

async def run_screener_analysis():
    """åŸ·è¡Œå¯¦éš›çš„åˆ†æå·¥ä½œä¸¦æ›´æ–°å¿«å– (é‡å‹ä»»å‹™)"""
    # å¦‚æœå·²ç¶“é–å®šï¼Œè¡¨ç¤ºæ­£åœ¨é‹è¡Œï¼Œç„¡éœ€é‡è¤‡
    if screener_lock.locked():
        logger.info("Screener analysis already in progress, skipping...")
        return
        
    async with screener_lock:
        logger.info("Starting heavy screener analysis...")
        try:
            exchange = SUPPORTED_EXCHANGES[0]
            loop = asyncio.get_running_loop()
            
            # åŸ·è¡Œé‡å‹åˆ†æä»»å‹™
            summary_df, top_performers, oversold, overbought = await loop.run_in_executor(
                None,
                lambda: screen_top_cryptos(
                    exchange=exchange,
                    limit=10, 
                    interval="1d",
                    target_symbols=None
                )
            )

            rename_map = {
                "Current Price": "Close", 
                "24h Change %": "price_change_24h",
                "7d Change %": "price_change_7d",
                "Signals": "signals"
            }
            
            top_performers = top_performers.rename(columns=rename_map).replace({np.nan: None})
            oversold = oversold.rename(columns=rename_map).replace({np.nan: None})
            overbought = overbought.rename(columns=rename_map).replace({np.nan: None})
            
            timestamp_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            cached_screener_result["timestamp"] = timestamp_str
            cached_screener_result["data"] = {
                "top_performers": top_performers.to_dict(orient="records"),
                "oversold": oversold.to_dict(orient="records"),
                "overbought": overbought.to_dict(orient="records"),
                "last_updated": timestamp_str
            }
            
            save_screener_cache(cached_screener_result)
            logger.info("Heavy screener analysis complete.")
            
        except Exception as e:
            logger.error(f"âŒ [åˆ†æä»»å‹™] åŸ·è¡Œå¤±æ•—: {e}")

async def update_screener_task():
    """
    èƒŒæ™¯ä»»å‹™ï¼š
    1. æ¯ç§’åŸ·è¡Œå¿«é€Ÿåƒ¹æ ¼æ›´æ–° (Fast Update)
    2. æ¯ 60 ç§’åŸ·è¡Œå®Œæ•´åˆ†æ (Heavy Analysis) - é™ä½é »ç‡ä»¥é¿å… API å°ç¦
    """
    logger.info("ğŸš€ Starting initial Screener analysis...")
    # Immediately run analysis on startup
    await run_screener_analysis()
    
    counter = 1
    while True:
        # æ¯ç§’éƒ½å˜—è©¦æ›´æ–°åƒ¹æ ¼
        asyncio.create_task(update_screener_prices_fast())
        
        # æ¯ 60 ç§’åŸ·è¡Œä¸€æ¬¡å®Œæ•´åˆ†æ
        if counter % 60 == 0:
            asyncio.create_task(run_screener_analysis())
        
        counter += 1
        await asyncio.sleep(1)


# --- [æ­£å¼ç‰ˆæ”¯ä»˜è¨»è§£å€å¡Š] ---
# ç•¶ä½ è¦æ­£å¼ä¸Šç·šä¸¦æ”¶æ¬¾æ™‚ï¼Œè«‹å–æ¶ˆä»¥ä¸‹ä»£ç¢¼çš„è¨»è§£ï¼Œä¸¦åœ¨ .env è¨­å®š PI_API_KEY
# PI_API_KEY = os.getenv("PI_API_KEY", "ä½ çš„_PI_API_KEY")
# PI_PLATFORM_API_URL = "https://api.minepi.com/v2"
# 
# class PaymentDTO(BaseModel):
#     paymentId: str
#     txid: Optional[str] = None
#
# @app.post("/api/payment/approve")
# async def approve_payment(data: PaymentDTO):
#     import requests
#     # å‘Šè¨´ Pi ä¼ºæœå™¨ä½ æº–å‚™å¥½æ¥å—é€™ç­†è¨‚å–®äº†
#     headers = {"Authorization": f"Key {PI_API_KEY}"}
#     resp = requests.post(f"{PI_PLATFORM_API_URL}/payments/{data.paymentId}/approve", headers=headers, json={})
#     return resp.json() if resp.status_code == 200 else {"error": "failed"}
#
# @app.post("/api/payment/complete")
# async def complete_payment(data: PaymentDTO):
#     import requests
#     # ç•¶ç”¨æˆ¶ç°½åæˆåŠŸå¾Œï¼Œæœ€å¾Œç¢ºèªäº¤æ˜“
#     headers = {"Authorization": f"Key {PI_API_KEY}"}
#     resp = requests.post(f"{PI_PLATFORM_API_URL}/payments/{data.paymentId}/complete", headers=headers, json={"txid": data.txid})
#     # åœ¨é€™è£¡ç™¼æ”¾ä½ çš„è™›æ“¬å•†å“ (ä¾‹å¦‚ï¼šé–‹é€š VIP åˆ†ææ¬Šé™)
#     return resp.json() if resp.status_code == 200 else {"error": "failed"}


# --- å·¥å…·å‡½æ•¸ ---

# å®šç¾©ä¸€å€‹å“¨å…µç‰©ä»¶ä¾†æ¨™è¨˜è¿­ä»£çµæŸ
_STOP_ITERATION_SENTINEL = object()

def _safe_next(iterator):
    """
    å®‰å…¨åœ°ç²å–ä¸‹ä¸€å€‹é …ç›®çš„è¼”åŠ©å‡½æ•¸ã€‚
    å¦‚æœé‡åˆ° StopIterationï¼Œå‰‡è¿”å›å“¨å…µç‰©ä»¶ï¼Œè€Œä¸æ˜¯æ‹‹å‡ºç•°å¸¸ã€‚
    é€™é¿å…äº† StopIteration ç•°å¸¸åœ¨ run_in_executor çš„ Future ä¸­å‚³éçš„å•é¡Œã€‚
    """
    try:
        return next(iterator)
    except StopIteration:
        return _STOP_ITERATION_SENTINEL

async def iterate_in_threadpool(generator):
    """
    å°‡åŒæ­¥ç”Ÿæˆå™¨åŒ…è£åœ¨åŸ·è¡Œç·’æ± ä¸­é‹è¡Œï¼Œå¯¦ç¾çœŸæ­£çš„ç•°æ­¥ä¸²æµã€‚
    è§£æ±ºé•·æ™‚é–“åˆ†æä»»å‹™é˜»å¡ä¸»åŸ·è¡Œç·’çš„å•é¡Œã€‚
    """
    loop = asyncio.get_running_loop()
    iterator = iter(generator)
    while True:
        try:
            # åœ¨é»˜èªåŸ·è¡Œç·’æ± ä¸­åŸ·è¡Œ _safe_next(iterator)
            # ä½¿ç”¨ _safe_next é¿å… StopIteration å‚³éçµ¦ Future
            item = await loop.run_in_executor(None, _safe_next, iterator)
            
            if item is _STOP_ITERATION_SENTINEL:
                break
                
            yield item
        except Exception as e:
            logger.error(f"ä¸²æµç”ŸæˆéŒ¯èª¤: {e}")
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
            break

# --- API ç«¯é» ---

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return {"status": "ok", "service": "Crypto Trading API"}

@app.post("/api/analyze")
async def analyze_crypto(request: QueryRequest):
    """
    è™•ç†åˆ†æè«‹æ±‚ï¼Œä¸¦ä»¥ä¸²æµ (Streaming) æ–¹å¼å›å‚³çµæœã€‚
    ä½¿ç”¨åŸ·è¡Œç·’æ± é¿å…é˜»å¡äº‹ä»¶å¾ªç’°ã€‚
    """
    if not bot:
        raise HTTPException(status_code=503, detail="åˆ†ææœå‹™å°šæœªå°±ç·’")

    logger.info(f"æ”¶åˆ°åˆ†æè«‹æ±‚: {request.message[:50]}... (Interval: {request.interval})")

    async def event_generator():
        try:
            # ä½¿ç”¨ iterate_in_threadpool å°‡åŒæ­¥ç”Ÿæˆå™¨è½‰ç‚ºç•°æ­¥
            async for part in iterate_in_threadpool(
                bot.process_message(request.message, request.interval, request.limit, request.manual_selection)
            ):
                # åŒ…è£æˆ JSON æ ¼å¼ç™¼é€çµ¦å‰ç«¯
                yield f"data: {json.dumps({'content': part})}\n\n"
            
            yield f"data: {json.dumps({'done': True})}\n\n"
        except Exception as e:
            logger.error(f"åˆ†æéç¨‹ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            yield f"data: {json.dumps({'error': 'Internal Server Error'})}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

@app.get("/api/config")
async def get_config():
    """å›å‚³å‰ç«¯éœ€è¦çš„é…ç½®è³‡è¨Š"""
    return {
        "supported_exchanges": SUPPORTED_EXCHANGES,
        "default_interval": DEFAULT_INTERVAL,
        "default_limit": DEFAULT_KLINES_LIMIT
    }

@app.get("/api/market/symbols")
async def get_market_symbols(exchange: str = "binance"):
    """Get all available symbols for a given exchange."""
    logger.info(f"Requesting symbol list for exchange: {exchange}")
    try:
        from data.data_fetcher import get_data_fetcher
        fetcher = get_data_fetcher(exchange)
        symbols = fetcher.get_all_symbols()
        logger.info(f"Successfully fetched {len(symbols)} symbols from {exchange}")
        return {"symbols": symbols}
    except Exception as e:
        logger.error(f"Failed to fetch symbols from {exchange}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/screener")
async def run_screener(request: ScreenerRequest):
    """å›å‚³å¸‚å ´ç¯©é¸æ•¸æ“š (å„ªå…ˆä½¿ç”¨å¿«å–ï¼Œä¸¦æ”¯æ´ç­‰å¾…èƒŒæ™¯ä»»å‹™)"""
    
    # 1. è‡ªå®šç¾©è«‹æ±‚ï¼šç›´æ¥åŸ·è¡Œ
    if request.symbols and len(request.symbols) > 0:
        logger.info(f"åŸ·è¡Œè‡ªå®šç¾©å¸‚å ´ç¯©é¸: {request.exchange}, Symbols: {len(request.symbols)}")
        try:
             loop = asyncio.get_running_loop()
             summary_df, top_performers, oversold, overbought = await loop.run_in_executor(
                None, 
                lambda: screen_top_cryptos(
                    exchange=request.exchange, 
                    limit=len(request.symbols), 
                    interval="1d",
                    target_symbols=request.symbols
                )
            )
             # ... formatting ...
             rename_map = {
                "Current Price": "Close", 
                "24h Change %": "price_change_24h", 
                "7d Change %": "price_change_7d", "Signals": "signals"
            }
             top_performers = top_performers.rename(columns=rename_map).replace({np.nan: None})
             oversold = oversold.rename(columns=rename_map).replace({np.nan: None})
             overbought = overbought.rename(columns=rename_map).replace({np.nan: None})
             return {
                "top_performers": top_performers.to_dict(orient="records"),
                "oversold": oversold.to_dict(orient="records"),
                "overbought": overbought.to_dict(orient="records"),
                "last_updated": datetime.now().isoformat()
            }
        except Exception as e:
             logger.error(f"è‡ªå®šç¾©ç¯©é¸å¤±æ•—: {e}", exc_info=True)
             raise HTTPException(status_code=500, detail=str(e))

    # 2. æª¢æŸ¥å¿«å–
    if cached_screener_result["data"] is not None:
        return cached_screener_result["data"]
    
    # 3. è‹¥å¿«å–ç‚ºç©ºï¼Œæª¢æŸ¥æ˜¯å¦èƒŒæ™¯ä»»å‹™æ­£åœ¨é‹è¡Œ
    if screener_lock.locked():
        logger.info("Cache empty, waiting for background analysis to complete...")
        async with screener_lock:
             # ç­‰å¾…é–é‡‹æ”¾å¾Œï¼Œå†æ¬¡æª¢æŸ¥å¿«å–
             if cached_screener_result["data"] is not None:
                 return cached_screener_result["data"]

    # 4. è‹¥ç­‰å¾…å¾Œä»ç„¡æ•¸æ“šï¼ˆæ¥µå°‘è¦‹ï¼‰ï¼Œæˆ–æœªé–å®šï¼Œå‰‡åŸ·è¡ŒåŒæ­¥æ›´æ–° (Double-check Locking)
    # ä½¿ç”¨é–é˜²æ­¢å¤šå€‹è«‹æ±‚åŒæ™‚è§¸ç™¼
    async with screener_lock:
        if cached_screener_result["data"] is not None:
            return cached_screener_result["data"]
            
        logger.info(f"ç„¡å¿«å–ä¸”ç„¡èƒŒæ™¯ä»»å‹™ï¼ŒåŸ·è¡Œå³æ™‚å¸‚å ´ç¯©é¸: {request.exchange}")
        try:
            loop = asyncio.get_running_loop()
            summary_df, top_performers, oversold, overbought = await loop.run_in_executor(
                None, 
                lambda: screen_top_cryptos(
                    exchange=request.exchange, 
                    limit=10, 
                    interval="1d",
                    target_symbols=None
                )
            )
            # ... formatting ...
            rename_map = {
                "Current Price": "Close", "24h Change %": "price_change_24h", 
                "7d Change %": "price_change_7d", "Signals": "signals"
            }
            top_performers = top_performers.rename(columns=rename_map).replace({np.nan: None})
            oversold = oversold.rename(columns=rename_map).replace({np.nan: None})
            overbought = overbought.rename(columns=rename_map).replace({np.nan: None})
            
            timestamp_str = datetime.now().isoformat()
            result_data = {
                "top_performers": top_performers.to_dict(orient="records"),
                "oversold": oversold.to_dict(orient="records"),
                "overbought": overbought.to_dict(orient="records"),
                "last_updated": timestamp_str
            }
            
            cached_screener_result["timestamp"] = timestamp_str
            cached_screener_result["data"] = result_data
            save_screener_cache(cached_screener_result)
            return result_data
        except Exception as e:
            logger.error(f"ç¯©é¸å™¨éŒ¯èª¤: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))

# --- è‡ªé¸æ¸…å–® API ---

@app.get("/api/watchlist/{user_id}")
async def get_user_watchlist(user_id: str):
    """ç²å–ç”¨æˆ¶çš„è‡ªé¸æ¸…å–®"""
    try:
        symbols = get_watchlist(user_id)
        return {"symbols": symbols}
    except Exception as e:
        logger.error(f"ç²å–è‡ªé¸æ¸…å–®å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç„¡æ³•ç²å–è‡ªé¸æ¸…å–®")

@app.post("/api/watchlist/add")
async def add_watchlist(request: WatchlistRequest):
    """æ–°å¢å¹£ç¨®åˆ°è‡ªé¸æ¸…å–®"""
    try:
        add_to_watchlist(request.user_id, request.symbol.upper())
        return {"success": True, "message": f"{request.symbol} å·²åŠ å…¥è‡ªé¸æ¸…å–®"}
    except Exception as e:
        logger.error(f"æ–°å¢è‡ªé¸æ¸…å–®å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="æ–°å¢å¤±æ•—")

@app.post("/api/watchlist/remove")
async def remove_watchlist(request: WatchlistRequest):
    """å¾è‡ªé¸æ¸…å–®ç§»é™¤å¹£ç¨®"""
    try:
        remove_from_watchlist(request.user_id, request.symbol.upper())
        return {"success": True, "message": f"{request.symbol} å·²å¾è‡ªé¸æ¸…å–®ç§»é™¤"}
    except Exception as e:
        logger.error(f"ç§»é™¤è‡ªé¸æ¸…å–®å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç§»é™¤å¤±æ•—")

# --- K ç·šæ•¸æ“š API (çµ¦åœ–è¡¨ä½¿ç”¨) ---

@app.post("/api/klines")
async def get_klines_data(request: KlineRequest):
    """ç²å– K ç·šæ•¸æ“šä¾›åœ–è¡¨é¡¯ç¤º"""
    try:
        loop = asyncio.get_running_loop()
        df = await loop.run_in_executor(
            None,
            lambda: get_klines(
                symbol=request.symbol,
                exchange=request.exchange,
                interval=request.interval,
                limit=request.limit
            )
        )

        if df is None or df.empty:
            raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ° {request.symbol} çš„æ•¸æ“š")

        klines = []
        for _, row in df.iterrows():
            klines.append({
                "time": int(row['timestamp'].timestamp()) if hasattr(row['timestamp'], 'timestamp') else int(row['timestamp'] / 1000),
                "open": float(row['open']),
                "high": float(row['high']),
                "low": float(row['low']),
                "close": float(row['close'])
            })

        return {
            "symbol": request.symbol,
            "interval": request.interval,
            "klines": klines
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç²å– K ç·šæ•¸æ“šå¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# --- å¸‚å ´è„ˆå‹• (Smart Attribution) API ---

@app.get("/api/market-pulse/{symbol}")
async def get_market_pulse_api(symbol: str, sources: Optional[str] = None):
    """
    ç²å–å¸‚å ´è„ˆå‹•åˆ†æã€‚
    ä½¿ç”¨ Symbol Lock é¿å…åŒä¸€æ™‚é–“å°åŒä¸€å¹£ç¨®é€²è¡Œé‡è¤‡çš„å³æ™‚åˆ†æã€‚
    """
    try:
        from analysis.market_pulse import get_market_pulse
        
        base_symbol = symbol.upper().replace("USDT", "").replace("BUSD", "").replace("-", "")
        
        # 1. å„ªå…ˆæª¢æŸ¥å¿«å–
        if base_symbol in MARKET_PULSE_CACHE:
            return MARKET_PULSE_CACHE[base_symbol]

        # 2. å¿«å–æœªå‘½ä¸­ï¼Œä½¿ç”¨é–é€²è¡ŒåŒæ­¥æ§åˆ¶
        lock = get_symbol_lock(base_symbol)
        
        async with lock:
            # Double check cache inside lock
            if base_symbol in MARKET_PULSE_CACHE:
                 return MARKET_PULSE_CACHE[base_symbol]

            logger.info(f"Cache miss for {base_symbol}, triggering immediate analysis...")
            
            loop = asyncio.get_running_loop()
            enabled_sources = sources.split(',') if sources else None
            
            result = await loop.run_in_executor(None, lambda: get_market_pulse(base_symbol, enabled_sources=enabled_sources))
            
            if "error" in result:
                raise HTTPException(status_code=404, detail=result["error"])
                
            MARKET_PULSE_CACHE[base_symbol] = result
            save_market_pulse_cache()
            
            return result
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¸‚å ´è„ˆå‹•åˆ†æå¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# --- AI è¾¯è«–è¦–è¦ºåŒ– (Visualized Debate) API ---
# ... (ä¿ç•™åŸæ¨£)
@app.get("/api/debate/{symbol}")
async def get_debate_analysis(symbol: str):
    """
    ç²å– AI è¾¯è«–è©³æƒ… (ç”¨æ–¼å‰ç«¯è¦–è¦ºåŒ–é¡¯ç¤º)ã€‚
    åŸ·è¡Œå®Œæ•´çš„ ReAct Agent æµç¨‹ï¼Œä½†åªå›å‚³è¾¯è«–ç›¸é—œçš„çµæ§‹åŒ–æ•¸æ“šã€‚
    """
    try:
        from core.graph import app as graph_app
        from core.tools import _find_available_exchange

        # 1. æº–å‚™åƒæ•¸
        clean_symbol = symbol.upper().replace("USDT", "").replace("BUSD", "").replace("-", "")
        exchange, normalized_symbol = _find_available_exchange(clean_symbol)
        
        if not exchange:
            raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ°äº¤æ˜“å° {clean_symbol}")

        state_input = {
            "symbol": normalized_symbol,
            "exchange": exchange,
            "interval": "1d",
            "limit": 100,
            "market_type": "spot",
            "leverage": 1,
            "include_multi_timeframe": True,
            "short_term_interval": "1h",
            "medium_term_interval": "4h",
            "long_term_interval": "1d",
            "preloaded_data": None,
            "account_balance": None,
            "selected_analysts": ["technical", "sentiment", "fundamental", "news"],
            "perform_trading_decision": True
        }

        logger.info(f"é–‹å§‹åŸ·è¡Œ AI è¾¯è«–åˆ†æ: {normalized_symbol}")

        # 2. åŸ·è¡Œåœ– (æ”¾å…¥åŸ·è¡Œç·’æ± )
        loop = asyncio.get_running_loop()
        result = await loop.run_in_executor(None, lambda: graph_app.invoke(state_input))
        
        # 3. æå–è¾¯è«–æ•¸æ“š
        # æ³¨æ„: result ä¸­çš„ç‰©ä»¶æ˜¯ Pydantic Modelï¼ŒFastAPI å¯ä»¥è‡ªå‹•åºåˆ—åŒ–ï¼Œä½†ç‚ºäº†ä¿éšªèµ·è¦‹ï¼Œæˆ‘å€‘å…ˆè½‰ dict
        response_data = {
            "symbol": normalized_symbol,
            "bull_argument": result.get("bull_argument"),
            "bear_argument": result.get("bear_argument"),
            "neutral_argument": result.get("neutral_argument"),
            "debate_judgment": result.get("debate_judgment"),
            "final_decision": result.get("final_approval")
        }
        
        return response_data

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"AI è¾¯è«–åˆ†æå¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# --- å›æ¸¬ (One-Click Backtest) API ---

@app.post("/api/backtest")
async def run_backtest_api(request: BacktestRequest):
    """
    åŸ·è¡Œå¿«é€Ÿå›æ¸¬ (One-Click Backtest)ã€‚
    é©—è­‰ç‰¹å®šæŠ€è¡“æŒ‡æ¨™ç­–ç•¥åœ¨éå»çš„è¡¨ç¾ã€‚
    """
    try:
        from analysis.simple_backtester import run_simple_backtest
        from core.tools import _normalize_symbol
        
        loop = asyncio.get_running_loop()
        
        # ç°¡å–®æ¨™æº–åŒ– symbol (å‡è¨­ OKX æˆ– Binance æ ¼å¼)
        # é€™è£¡æˆ‘å€‘å‡è¨­ simple_backtester èƒ½è™•ç†ï¼Œæˆ–è€…æˆ‘å€‘éœ€è¦å…ˆæ¨™æº–åŒ–
        # æˆ‘å€‘ç›´æ¥å‚³å…¥ç”¨æˆ¶è¼¸å…¥çš„ symbolï¼Œè®“ backtester å…§éƒ¨çš„ data_fetcher å»è™•ç†
        # ä½†ç‚ºäº†ä¿éšªï¼Œæˆ‘å€‘å¯ä»¥åšä¸€é»åŸºæœ¬çš„æ¸…ç†
        clean_symbol = request.symbol.upper().replace("USDT", "").replace("BUSD", "").replace("-", "")
        # é è¨­åŠ ä¸Š -USDT çµ¦ OKX data fetcher (å¦‚æœå®ƒéœ€è¦)
        # æ ¹æ“š analysis/simple_backtester.py é‚è¼¯ï¼Œå®ƒèª¿ç”¨ get_data_fetcher("okx")
        # OKX fetcher é€šå¸¸é æœŸ "BTC-USDT" æ ¼å¼
        target_symbol = f"{clean_symbol}-USDT"
        
        logger.info(f"é–‹å§‹åŸ·è¡Œå›æ¸¬: {target_symbol} ({request.signal_type})")
        
        result = await loop.run_in_executor(
            None, 
            lambda: run_simple_backtest(
                symbol=target_symbol,
                signal_type=request.signal_type,
                interval=request.interval,
                limit=1000 # å›ºå®šå›æ¸¬éå» 1000 æ ¹ K ç·š
            )
        )
        
        if "error" in result:
             raise HTTPException(status_code=400, detail=result["error"])
             
        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å›æ¸¬åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# --- éœæ…‹æª”æ¡ˆèˆ‡é é¢ ---

if os.path.exists("web"):
    app.mount("/static", StaticFiles(directory="web"), name="static")

@app.get("/")
async def read_index():
    """è¿”å›ä¸»é é¢ index.html"""
    if os.path.exists("web/index.html"):
        return FileResponse("web/index.html")
    return {"message": "Welcome to Crypto API. Frontend not found."}

if __name__ == "__main__":
    logger.info("ğŸš€ Pi Crypto Insight API Server å•Ÿå‹•ä¸­...")
    logger.info(f"ğŸ  æœ¬åœ°ç¶²å€: http://localhost:8111")
    logger.info("ğŸ“± è«‹åœ¨ Pi Browser ä¸­ä½¿ç”¨ HTTPS ç¶²å€è¨ªå• (å¦‚é€é ngrok)")
    uvicorn.run(app, host="0.0.0.0", port=8111)